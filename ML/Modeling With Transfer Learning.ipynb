{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_plot(item_dir, top=10):\n",
    "    all_item_dirs = os.listdir(item_dir)\n",
    "    item_files = [os.path.join(item_dir, file) for file in all_item_dirs[:5]]\n",
    "    \n",
    "    plt.figure(figsize=(12,14))\n",
    "    \n",
    "    for idx, img_path in enumerate(item_files):\n",
    "        plt.subplot(5,5,idx+1)\n",
    "        \n",
    "        img=plt.imread(img_path)\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glass', 'trash', 'plastic', 'cardboard', 'paper', 'metal']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('Garbage classification/Garbage classification'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Garbage classification/Garbage classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x1008 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_plot(data_path+'/glass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, validation_split=0.15, rescale=1./255,\n",
    "                           shear_range=0.1,zoom_range=0.1, width_shift_range=0.1,height_shift_range=0.1)\n",
    "\n",
    "test = ImageDataGenerator(rescale=1./255, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2150 images belonging to 6 classes.\n",
      "Found 377 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train.flow_from_directory(data_path,target_size=(150,150),batch_size=32, class_mode='categorical',\n",
    "                                            subset='training')\n",
    "\n",
    "test_generator = test.flow_from_directory(data_path,target_size=(150,150),batch_size=32, class_mode='categorical',\n",
    "                                            subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'cardboard', 1: 'glass', 2: 'metal', 3: 'paper', 4: 'plastic', 5: 'trash'}\n"
     ]
    }
   ],
   "source": [
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 300, 300, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 150, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 150, 150, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 75, 75, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 43808)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                2803776   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 2,842,022\n",
      "Trainable params: 2,842,022\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Conv2D(32,(3,3),padding='same',input_shape=(300,300,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32,(3,3),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='garbage_model.h5'\n",
    "checkpoint1 = ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size_train = train_generator.n//train_generator.batch_size\n",
    "step_size_test = test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-83f4f44ede1f>:2: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.7414 - accuracy: 0.2411\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.30682, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 137s 2s/step - loss: 1.7414 - accuracy: 0.2411 - val_loss: 1.6808 - val_accuracy: 0.3068\n",
      "Epoch 2/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.6942 - accuracy: 0.2483\n",
      "Epoch 00002: val_accuracy did not improve from 0.30682\n",
      "67/67 [==============================] - 118s 2s/step - loss: 1.6942 - accuracy: 0.2483 - val_loss: 1.6371 - val_accuracy: 0.2983\n",
      "Epoch 3/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.6627 - accuracy: 0.2993\n",
      "Epoch 00003: val_accuracy improved from 0.30682 to 0.32386, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 127s 2s/step - loss: 1.6627 - accuracy: 0.2993 - val_loss: 1.6129 - val_accuracy: 0.3239\n",
      "Epoch 4/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.5387 - accuracy: 0.3602\n",
      "Epoch 00004: val_accuracy improved from 0.32386 to 0.35227, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 118s 2s/step - loss: 1.5387 - accuracy: 0.3602 - val_loss: 1.5278 - val_accuracy: 0.3523\n",
      "Epoch 5/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.4712 - accuracy: 0.4051\n",
      "Epoch 00005: val_accuracy improved from 0.35227 to 0.38068, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 116s 2s/step - loss: 1.4712 - accuracy: 0.4051 - val_loss: 1.4748 - val_accuracy: 0.3807\n",
      "Epoch 6/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.4188 - accuracy: 0.4263\n",
      "Epoch 00006: val_accuracy improved from 0.38068 to 0.39773, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 117s 2s/step - loss: 1.4188 - accuracy: 0.4263 - val_loss: 1.4353 - val_accuracy: 0.3977\n",
      "Epoch 7/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.3800 - accuracy: 0.4476\n",
      "Epoch 00007: val_accuracy did not improve from 0.39773\n",
      "67/67 [==============================] - 117s 2s/step - loss: 1.3800 - accuracy: 0.4476 - val_loss: 1.3934 - val_accuracy: 0.3977\n",
      "Epoch 8/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.3409 - accuracy: 0.4509\n",
      "Epoch 00008: val_accuracy improved from 0.39773 to 0.41761, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 116s 2s/step - loss: 1.3409 - accuracy: 0.4509 - val_loss: 1.4302 - val_accuracy: 0.4176\n",
      "Epoch 9/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.3439 - accuracy: 0.4462\n",
      "Epoch 00009: val_accuracy improved from 0.41761 to 0.45170, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 117s 2s/step - loss: 1.3439 - accuracy: 0.4462 - val_loss: 1.3406 - val_accuracy: 0.4517\n",
      "Epoch 10/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.3367 - accuracy: 0.4594\n",
      "Epoch 00010: val_accuracy improved from 0.45170 to 0.45739, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 117s 2s/step - loss: 1.3367 - accuracy: 0.4594 - val_loss: 1.3098 - val_accuracy: 0.4574\n",
      "Epoch 11/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.3163 - accuracy: 0.4769\n",
      "Epoch 00011: val_accuracy did not improve from 0.45739\n",
      "67/67 [==============================] - 116s 2s/step - loss: 1.3163 - accuracy: 0.4769 - val_loss: 1.3769 - val_accuracy: 0.4290\n",
      "Epoch 12/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.2761 - accuracy: 0.4991\n",
      "Epoch 00012: val_accuracy did not improve from 0.45739\n",
      "67/67 [==============================] - 116s 2s/step - loss: 1.2761 - accuracy: 0.4991 - val_loss: 1.3066 - val_accuracy: 0.4432\n",
      "Epoch 13/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.2589 - accuracy: 0.4958\n",
      "Epoch 00013: val_accuracy improved from 0.45739 to 0.46307, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 118s 2s/step - loss: 1.2589 - accuracy: 0.4958 - val_loss: 1.3135 - val_accuracy: 0.4631\n",
      "Epoch 14/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.2303 - accuracy: 0.5061\n",
      "Epoch 00014: val_accuracy improved from 0.46307 to 0.51989, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 118s 2s/step - loss: 1.2303 - accuracy: 0.5061 - val_loss: 1.2517 - val_accuracy: 0.5199\n",
      "Epoch 15/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.2199 - accuracy: 0.5227\n",
      "Epoch 00015: val_accuracy did not improve from 0.51989\n",
      "67/67 [==============================] - 116s 2s/step - loss: 1.2199 - accuracy: 0.5227 - val_loss: 1.2747 - val_accuracy: 0.5170\n",
      "Epoch 16/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.1830 - accuracy: 0.5288\n",
      "Epoch 00016: val_accuracy did not improve from 0.51989\n",
      "67/67 [==============================] - 117s 2s/step - loss: 1.1830 - accuracy: 0.5288 - val_loss: 1.3403 - val_accuracy: 0.4858\n",
      "Epoch 17/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.1905 - accuracy: 0.5378\n",
      "Epoch 00017: val_accuracy did not improve from 0.51989\n",
      "67/67 [==============================] - 115s 2s/step - loss: 1.1905 - accuracy: 0.5378 - val_loss: 1.2731 - val_accuracy: 0.5057\n",
      "Epoch 18/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.2189 - accuracy: 0.5146\n",
      "Epoch 00018: val_accuracy improved from 0.51989 to 0.52841, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 117s 2s/step - loss: 1.2189 - accuracy: 0.5146 - val_loss: 1.2310 - val_accuracy: 0.5284\n",
      "Epoch 19/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.1777 - accuracy: 0.5538\n",
      "Epoch 00019: val_accuracy did not improve from 0.52841\n",
      "67/67 [==============================] - 116s 2s/step - loss: 1.1777 - accuracy: 0.5538 - val_loss: 1.3137 - val_accuracy: 0.4915\n",
      "Epoch 20/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.1733 - accuracy: 0.5477\n",
      "Epoch 00020: val_accuracy did not improve from 0.52841\n",
      "67/67 [==============================] - 117s 2s/step - loss: 1.1733 - accuracy: 0.5477 - val_loss: 1.2688 - val_accuracy: 0.5028\n",
      "Epoch 21/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.1693 - accuracy: 0.5453\n",
      "Epoch 00021: val_accuracy did not improve from 0.52841\n",
      "67/67 [==============================] - 120s 2s/step - loss: 1.1693 - accuracy: 0.5453 - val_loss: 1.2411 - val_accuracy: 0.5284\n",
      "Epoch 22/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.1209 - accuracy: 0.5685\n",
      "Epoch 00022: val_accuracy did not improve from 0.52841\n",
      "67/67 [==============================] - 118s 2s/step - loss: 1.1209 - accuracy: 0.5685 - val_loss: 1.3089 - val_accuracy: 0.5000\n",
      "Epoch 23/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.1890 - accuracy: 0.5496\n",
      "Epoch 00023: val_accuracy did not improve from 0.52841\n",
      "67/67 [==============================] - 117s 2s/step - loss: 1.1890 - accuracy: 0.5496 - val_loss: 1.3312 - val_accuracy: 0.4915\n",
      "Epoch 24/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.1678 - accuracy: 0.5312\n",
      "Epoch 00024: val_accuracy did not improve from 0.52841\n",
      "67/67 [==============================] - 119s 2s/step - loss: 1.1678 - accuracy: 0.5312 - val_loss: 1.3079 - val_accuracy: 0.4801\n",
      "Epoch 25/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.1510 - accuracy: 0.5628\n",
      "Epoch 00025: val_accuracy did not improve from 0.52841\n",
      "67/67 [==============================] - 118s 2s/step - loss: 1.1510 - accuracy: 0.5628 - val_loss: 1.2548 - val_accuracy: 0.4886\n",
      "Epoch 26/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.0880 - accuracy: 0.5935\n",
      "Epoch 00026: val_accuracy improved from 0.52841 to 0.54261, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 117s 2s/step - loss: 1.0880 - accuracy: 0.5935 - val_loss: 1.2143 - val_accuracy: 0.5426\n",
      "Epoch 27/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.0792 - accuracy: 0.5916\n",
      "Epoch 00027: val_accuracy did not improve from 0.54261\n",
      "67/67 [==============================] - 118s 2s/step - loss: 1.0792 - accuracy: 0.5916 - val_loss: 1.2658 - val_accuracy: 0.5085\n",
      "Epoch 28/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.0807 - accuracy: 0.5803\n",
      "Epoch 00028: val_accuracy improved from 0.54261 to 0.54545, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 118s 2s/step - loss: 1.0807 - accuracy: 0.5803 - val_loss: 1.2487 - val_accuracy: 0.5455\n",
      "Epoch 29/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.0782 - accuracy: 0.6015\n",
      "Epoch 00029: val_accuracy improved from 0.54545 to 0.58239, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 117s 2s/step - loss: 1.0782 - accuracy: 0.6015 - val_loss: 1.2104 - val_accuracy: 0.5824\n",
      "Epoch 30/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.0808 - accuracy: 0.5949\n",
      "Epoch 00030: val_accuracy did not improve from 0.58239\n",
      "67/67 [==============================] - 118s 2s/step - loss: 1.0808 - accuracy: 0.5949 - val_loss: 1.2737 - val_accuracy: 0.5511\n",
      "Epoch 31/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9799 - accuracy: 0.6393\n",
      "Epoch 00031: val_accuracy did not improve from 0.58239\n",
      "67/67 [==============================] - 117s 2s/step - loss: 0.9799 - accuracy: 0.6393 - val_loss: 1.3304 - val_accuracy: 0.5625\n",
      "Epoch 32/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9976 - accuracy: 0.6284\n",
      "Epoch 00032: val_accuracy did not improve from 0.58239\n",
      "67/67 [==============================] - 117s 2s/step - loss: 0.9976 - accuracy: 0.6284 - val_loss: 1.1990 - val_accuracy: 0.5568\n",
      "Epoch 33/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.0174 - accuracy: 0.6176\n",
      "Epoch 00033: val_accuracy did not improve from 0.58239\n",
      "67/67 [==============================] - 117s 2s/step - loss: 1.0174 - accuracy: 0.6176 - val_loss: 1.1575 - val_accuracy: 0.5824\n",
      "Epoch 34/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9864 - accuracy: 0.6402\n",
      "Epoch 00034: val_accuracy improved from 0.58239 to 0.59091, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.9864 - accuracy: 0.6402 - val_loss: 1.1432 - val_accuracy: 0.5909\n",
      "Epoch 35/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.0096 - accuracy: 0.6280\n",
      "Epoch 00035: val_accuracy did not improve from 0.59091\n",
      "67/67 [==============================] - 116s 2s/step - loss: 1.0096 - accuracy: 0.6280 - val_loss: 1.2713 - val_accuracy: 0.5511\n",
      "Epoch 36/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9474 - accuracy: 0.6539\n",
      "Epoch 00036: val_accuracy improved from 0.59091 to 0.60795, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 119s 2s/step - loss: 0.9474 - accuracy: 0.6539 - val_loss: 1.2175 - val_accuracy: 0.6080\n",
      "Epoch 37/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9521 - accuracy: 0.6582\n",
      "Epoch 00037: val_accuracy did not improve from 0.60795\n",
      "67/67 [==============================] - 117s 2s/step - loss: 0.9521 - accuracy: 0.6582 - val_loss: 1.2929 - val_accuracy: 0.5710\n",
      "Epoch 38/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9404 - accuracy: 0.6619\n",
      "Epoch 00038: val_accuracy did not improve from 0.60795\n",
      "67/67 [==============================] - 118s 2s/step - loss: 0.9404 - accuracy: 0.6619 - val_loss: 1.1110 - val_accuracy: 0.5795\n",
      "Epoch 39/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9453 - accuracy: 0.6412\n",
      "Epoch 00039: val_accuracy did not improve from 0.60795\n",
      "67/67 [==============================] - 117s 2s/step - loss: 0.9453 - accuracy: 0.6412 - val_loss: 1.2059 - val_accuracy: 0.5739\n",
      "Epoch 40/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9914 - accuracy: 0.6369\n",
      "Epoch 00040: val_accuracy did not improve from 0.60795\n",
      "67/67 [==============================] - 118s 2s/step - loss: 0.9914 - accuracy: 0.6369 - val_loss: 1.1626 - val_accuracy: 0.5881\n",
      "Epoch 41/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9825 - accuracy: 0.6416\n",
      "Epoch 00041: val_accuracy did not improve from 0.60795\n",
      "67/67 [==============================] - 117s 2s/step - loss: 0.9825 - accuracy: 0.6416 - val_loss: 1.1418 - val_accuracy: 0.5994\n",
      "Epoch 42/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9073 - accuracy: 0.6634\n",
      "Epoch 00042: val_accuracy did not improve from 0.60795\n",
      "67/67 [==============================] - 117s 2s/step - loss: 0.9073 - accuracy: 0.6634 - val_loss: 1.2145 - val_accuracy: 0.5909\n",
      "Epoch 43/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9224 - accuracy: 0.6601\n",
      "Epoch 00043: val_accuracy improved from 0.60795 to 0.61364, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 118s 2s/step - loss: 0.9224 - accuracy: 0.6601 - val_loss: 1.1331 - val_accuracy: 0.6136\n",
      "Epoch 44/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9306 - accuracy: 0.6610\n",
      "Epoch 00044: val_accuracy did not improve from 0.61364\n",
      "67/67 [==============================] - 120s 2s/step - loss: 0.9306 - accuracy: 0.6610 - val_loss: 1.0950 - val_accuracy: 0.5909\n",
      "Epoch 45/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9555 - accuracy: 0.6407\n",
      "Epoch 00045: val_accuracy did not improve from 0.61364\n",
      "67/67 [==============================] - 117s 2s/step - loss: 0.9555 - accuracy: 0.6407 - val_loss: 1.1404 - val_accuracy: 0.5795\n",
      "Epoch 46/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9481 - accuracy: 0.6686\n",
      "Epoch 00046: val_accuracy did not improve from 0.61364\n",
      "67/67 [==============================] - 118s 2s/step - loss: 0.9481 - accuracy: 0.6686 - val_loss: 1.3098 - val_accuracy: 0.6023\n",
      "Epoch 47/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8999 - accuracy: 0.6723\n",
      "Epoch 00047: val_accuracy did not improve from 0.61364\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.8999 - accuracy: 0.6723 - val_loss: 1.0602 - val_accuracy: 0.5994\n",
      "Epoch 48/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9475 - accuracy: 0.6582\n",
      "Epoch 00048: val_accuracy improved from 0.61364 to 0.64773, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.9475 - accuracy: 0.6582 - val_loss: 1.1078 - val_accuracy: 0.6477\n",
      "Epoch 49/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8522 - accuracy: 0.6893\n",
      "Epoch 00049: val_accuracy did not improve from 0.64773\n",
      "67/67 [==============================] - 119s 2s/step - loss: 0.8522 - accuracy: 0.6893 - val_loss: 1.0823 - val_accuracy: 0.6278\n",
      "Epoch 50/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8722 - accuracy: 0.6808\n",
      "Epoch 00050: val_accuracy did not improve from 0.64773\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.8722 - accuracy: 0.6808 - val_loss: 1.0709 - val_accuracy: 0.6136\n",
      "Epoch 51/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8489 - accuracy: 0.6907\n",
      "Epoch 00051: val_accuracy did not improve from 0.64773\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.8489 - accuracy: 0.6907 - val_loss: 1.0681 - val_accuracy: 0.6335\n",
      "Epoch 52/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8767 - accuracy: 0.6799\n",
      "Epoch 00052: val_accuracy did not improve from 0.64773\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.8767 - accuracy: 0.6799 - val_loss: 1.1312 - val_accuracy: 0.6335\n",
      "Epoch 53/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8786 - accuracy: 0.6799\n",
      "Epoch 00053: val_accuracy did not improve from 0.64773\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.8786 - accuracy: 0.6799 - val_loss: 1.1741 - val_accuracy: 0.6193\n",
      "Epoch 54/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8944 - accuracy: 0.6846\n",
      "Epoch 00054: val_accuracy did not improve from 0.64773\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.8944 - accuracy: 0.6846 - val_loss: 1.2862 - val_accuracy: 0.6108\n",
      "Epoch 55/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8452 - accuracy: 0.7002\n",
      "Epoch 00055: val_accuracy did not improve from 0.64773\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.8452 - accuracy: 0.7002 - val_loss: 1.1975 - val_accuracy: 0.6278\n",
      "Epoch 56/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8628 - accuracy: 0.6860\n",
      "Epoch 00056: val_accuracy did not improve from 0.64773\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.8628 - accuracy: 0.6860 - val_loss: 1.1680 - val_accuracy: 0.6193\n",
      "Epoch 57/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8393 - accuracy: 0.6898\n",
      "Epoch 00057: val_accuracy did not improve from 0.64773\n",
      "67/67 [==============================] - 117s 2s/step - loss: 0.8393 - accuracy: 0.6898 - val_loss: 1.1006 - val_accuracy: 0.6364\n",
      "Epoch 58/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8269 - accuracy: 0.7082\n",
      "Epoch 00058: val_accuracy did not improve from 0.64773\n",
      "67/67 [==============================] - 117s 2s/step - loss: 0.8269 - accuracy: 0.7082 - val_loss: 1.1017 - val_accuracy: 0.6477\n",
      "Epoch 59/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.9009 - accuracy: 0.6605\n",
      "Epoch 00059: val_accuracy did not improve from 0.64773\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.9009 - accuracy: 0.6605 - val_loss: 1.1824 - val_accuracy: 0.6250\n",
      "Epoch 60/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8548 - accuracy: 0.6959\n",
      "Epoch 00060: val_accuracy did not improve from 0.64773\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.8548 - accuracy: 0.6959 - val_loss: 1.1452 - val_accuracy: 0.6051\n",
      "Epoch 61/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8559 - accuracy: 0.6813\n",
      "Epoch 00061: val_accuracy did not improve from 0.64773\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.8559 - accuracy: 0.6813 - val_loss: 1.0436 - val_accuracy: 0.6477\n",
      "Epoch 62/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8331 - accuracy: 0.6846\n",
      "Epoch 00062: val_accuracy did not improve from 0.64773\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.8331 - accuracy: 0.6846 - val_loss: 1.0206 - val_accuracy: 0.6392\n",
      "Epoch 63/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8284 - accuracy: 0.6907\n",
      "Epoch 00063: val_accuracy did not improve from 0.64773\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.8284 - accuracy: 0.6907 - val_loss: 1.0925 - val_accuracy: 0.6392\n",
      "Epoch 64/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8409 - accuracy: 0.7030\n",
      "Epoch 00064: val_accuracy did not improve from 0.64773\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.8409 - accuracy: 0.7030 - val_loss: 1.1536 - val_accuracy: 0.6193\n",
      "Epoch 65/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7954 - accuracy: 0.7040\n",
      "Epoch 00065: val_accuracy improved from 0.64773 to 0.66193, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.7954 - accuracy: 0.7040 - val_loss: 1.1288 - val_accuracy: 0.6619\n",
      "Epoch 66/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8348 - accuracy: 0.7030\n",
      "Epoch 00066: val_accuracy did not improve from 0.66193\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.8348 - accuracy: 0.7030 - val_loss: 1.1270 - val_accuracy: 0.6023\n",
      "Epoch 67/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8109 - accuracy: 0.7129\n",
      "Epoch 00067: val_accuracy did not improve from 0.66193\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.8109 - accuracy: 0.7129 - val_loss: 1.0548 - val_accuracy: 0.6477\n",
      "Epoch 68/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7985 - accuracy: 0.7158\n",
      "Epoch 00068: val_accuracy improved from 0.66193 to 0.67330, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.7985 - accuracy: 0.7158 - val_loss: 0.9803 - val_accuracy: 0.6733\n",
      "Epoch 69/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8411 - accuracy: 0.7062\n",
      "Epoch 00069: val_accuracy did not improve from 0.67330\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.8411 - accuracy: 0.7062 - val_loss: 1.1690 - val_accuracy: 0.6023\n",
      "Epoch 70/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8652 - accuracy: 0.6912\n",
      "Epoch 00070: val_accuracy improved from 0.67330 to 0.68182, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.8652 - accuracy: 0.6912 - val_loss: 1.0776 - val_accuracy: 0.6818\n",
      "Epoch 71/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7993 - accuracy: 0.6978\n",
      "Epoch 00071: val_accuracy did not improve from 0.68182\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.7993 - accuracy: 0.6978 - val_loss: 1.1752 - val_accuracy: 0.6534\n",
      "Epoch 72/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7937 - accuracy: 0.7186\n",
      "Epoch 00072: val_accuracy did not improve from 0.68182\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.7937 - accuracy: 0.7186 - val_loss: 1.1063 - val_accuracy: 0.6676\n",
      "Epoch 73/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.8157 - accuracy: 0.7025\n",
      "Epoch 00073: val_accuracy improved from 0.68182 to 0.69034, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.8157 - accuracy: 0.7025 - val_loss: 1.0454 - val_accuracy: 0.6903\n",
      "Epoch 74/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7731 - accuracy: 0.7214\n",
      "Epoch 00074: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.7731 - accuracy: 0.7214 - val_loss: 1.2749 - val_accuracy: 0.5966\n",
      "Epoch 75/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7637 - accuracy: 0.7285\n",
      "Epoch 00075: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.7637 - accuracy: 0.7285 - val_loss: 1.0623 - val_accuracy: 0.6676\n",
      "Epoch 76/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7085 - accuracy: 0.7540\n",
      "Epoch 00076: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 118s 2s/step - loss: 0.7085 - accuracy: 0.7540 - val_loss: 1.0259 - val_accuracy: 0.6705\n",
      "Epoch 77/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7841 - accuracy: 0.7148\n",
      "Epoch 00077: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.7841 - accuracy: 0.7148 - val_loss: 1.1900 - val_accuracy: 0.6534\n",
      "Epoch 78/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7725 - accuracy: 0.7224\n",
      "Epoch 00078: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.7725 - accuracy: 0.7224 - val_loss: 1.2605 - val_accuracy: 0.6420\n",
      "Epoch 79/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7715 - accuracy: 0.7101\n",
      "Epoch 00079: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 121s 2s/step - loss: 0.7715 - accuracy: 0.7101 - val_loss: 1.0116 - val_accuracy: 0.6562\n",
      "Epoch 80/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7637 - accuracy: 0.7280\n",
      "Epoch 00080: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 116s 2s/step - loss: 0.7637 - accuracy: 0.7280 - val_loss: 1.1882 - val_accuracy: 0.6619\n",
      "Epoch 81/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7704 - accuracy: 0.7299\n",
      "Epoch 00081: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.7704 - accuracy: 0.7299 - val_loss: 1.0635 - val_accuracy: 0.6335\n",
      "Epoch 82/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7631 - accuracy: 0.7101\n",
      "Epoch 00082: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.7631 - accuracy: 0.7101 - val_loss: 1.1159 - val_accuracy: 0.6506\n",
      "Epoch 83/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7668 - accuracy: 0.7257\n",
      "Epoch 00083: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.7668 - accuracy: 0.7257 - val_loss: 1.0933 - val_accuracy: 0.6307\n",
      "Epoch 84/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7765 - accuracy: 0.7195\n",
      "Epoch 00084: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.7765 - accuracy: 0.7195 - val_loss: 1.1245 - val_accuracy: 0.6278\n",
      "Epoch 85/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7626 - accuracy: 0.7262\n",
      "Epoch 00085: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.7626 - accuracy: 0.7262 - val_loss: 1.1173 - val_accuracy: 0.6420\n",
      "Epoch 86/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7574 - accuracy: 0.7290\n",
      "Epoch 00086: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.7574 - accuracy: 0.7290 - val_loss: 1.0969 - val_accuracy: 0.6506\n",
      "Epoch 87/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7635 - accuracy: 0.7262\n",
      "Epoch 00087: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.7635 - accuracy: 0.7262 - val_loss: 1.0827 - val_accuracy: 0.6136\n",
      "Epoch 88/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7357 - accuracy: 0.7408\n",
      "Epoch 00088: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.7357 - accuracy: 0.7408 - val_loss: 1.2448 - val_accuracy: 0.6534\n",
      "Epoch 89/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7488 - accuracy: 0.7314\n",
      "Epoch 00089: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 118s 2s/step - loss: 0.7488 - accuracy: 0.7314 - val_loss: 1.1489 - val_accuracy: 0.6534\n",
      "Epoch 90/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7331 - accuracy: 0.7375\n",
      "Epoch 00090: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 115s 2s/step - loss: 0.7331 - accuracy: 0.7375 - val_loss: 1.3458 - val_accuracy: 0.6307\n",
      "Epoch 91/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7440 - accuracy: 0.7295\n",
      "Epoch 00091: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.7440 - accuracy: 0.7295 - val_loss: 1.1841 - val_accuracy: 0.6392\n",
      "Epoch 92/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6922 - accuracy: 0.7455\n",
      "Epoch 00092: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.6922 - accuracy: 0.7455 - val_loss: 1.1725 - val_accuracy: 0.6847\n",
      "Epoch 93/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7145 - accuracy: 0.7427\n",
      "Epoch 00093: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.7145 - accuracy: 0.7427 - val_loss: 1.1495 - val_accuracy: 0.6761\n",
      "Epoch 94/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7085 - accuracy: 0.7427\n",
      "Epoch 00094: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.7085 - accuracy: 0.7427 - val_loss: 1.1593 - val_accuracy: 0.6619\n",
      "Epoch 95/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7849 - accuracy: 0.7186\n",
      "Epoch 00095: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.7849 - accuracy: 0.7186 - val_loss: 1.1422 - val_accuracy: 0.6648\n",
      "Epoch 96/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7246 - accuracy: 0.7422\n",
      "Epoch 00096: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.7246 - accuracy: 0.7422 - val_loss: 1.1249 - val_accuracy: 0.6591\n",
      "Epoch 97/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6962 - accuracy: 0.7493\n",
      "Epoch 00097: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 124s 2s/step - loss: 0.6962 - accuracy: 0.7493 - val_loss: 1.2376 - val_accuracy: 0.6477\n",
      "Epoch 98/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7180 - accuracy: 0.7403\n",
      "Epoch 00098: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 126s 2s/step - loss: 0.7180 - accuracy: 0.7403 - val_loss: 1.1098 - val_accuracy: 0.6847\n",
      "Epoch 99/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.7521\n",
      "Epoch 00099: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 126s 2s/step - loss: 0.6848 - accuracy: 0.7521 - val_loss: 1.1721 - val_accuracy: 0.6364\n",
      "Epoch 100/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7512 - accuracy: 0.7370\n",
      "Epoch 00100: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 124s 2s/step - loss: 0.7512 - accuracy: 0.7370 - val_loss: 1.2639 - val_accuracy: 0.6477\n",
      "Epoch 101/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7203 - accuracy: 0.7422\n",
      "Epoch 00101: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 125s 2s/step - loss: 0.7203 - accuracy: 0.7422 - val_loss: 1.1183 - val_accuracy: 0.6619\n",
      "Epoch 102/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6988 - accuracy: 0.7469\n",
      "Epoch 00102: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 126s 2s/step - loss: 0.6988 - accuracy: 0.7469 - val_loss: 1.1217 - val_accuracy: 0.6591\n",
      "Epoch 103/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7563 - accuracy: 0.7351\n",
      "Epoch 00103: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 124s 2s/step - loss: 0.7563 - accuracy: 0.7351 - val_loss: 1.0750 - val_accuracy: 0.6619\n",
      "Epoch 104/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6686 - accuracy: 0.7663\n",
      "Epoch 00104: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 126s 2s/step - loss: 0.6686 - accuracy: 0.7663 - val_loss: 1.1932 - val_accuracy: 0.6705\n",
      "Epoch 105/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6668 - accuracy: 0.7644\n",
      "Epoch 00105: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 127s 2s/step - loss: 0.6668 - accuracy: 0.7644 - val_loss: 1.2017 - val_accuracy: 0.6761\n",
      "Epoch 106/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6591 - accuracy: 0.7720\n",
      "Epoch 00106: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 125s 2s/step - loss: 0.6591 - accuracy: 0.7720 - val_loss: 1.1256 - val_accuracy: 0.6562\n",
      "Epoch 107/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7570 - accuracy: 0.7266\n",
      "Epoch 00107: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 124s 2s/step - loss: 0.7570 - accuracy: 0.7266 - val_loss: 1.0398 - val_accuracy: 0.6847\n",
      "Epoch 108/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6957 - accuracy: 0.7550\n",
      "Epoch 00108: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.6957 - accuracy: 0.7550 - val_loss: 1.0707 - val_accuracy: 0.6903\n",
      "Epoch 109/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6798 - accuracy: 0.7616\n",
      "Epoch 00109: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 126s 2s/step - loss: 0.6798 - accuracy: 0.7616 - val_loss: 1.0233 - val_accuracy: 0.6761\n",
      "Epoch 110/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6816 - accuracy: 0.7583\n",
      "Epoch 00110: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.6816 - accuracy: 0.7583 - val_loss: 1.3622 - val_accuracy: 0.6562\n",
      "Epoch 111/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7001 - accuracy: 0.7441\n",
      "Epoch 00111: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 124s 2s/step - loss: 0.7001 - accuracy: 0.7441 - val_loss: 1.2760 - val_accuracy: 0.6506\n",
      "Epoch 112/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6745 - accuracy: 0.7531\n",
      "Epoch 00112: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 125s 2s/step - loss: 0.6745 - accuracy: 0.7531 - val_loss: 1.0661 - val_accuracy: 0.6619\n",
      "Epoch 113/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6492 - accuracy: 0.7620\n",
      "Epoch 00113: val_accuracy did not improve from 0.69034\n",
      "67/67 [==============================] - 126s 2s/step - loss: 0.6492 - accuracy: 0.7620 - val_loss: 1.1401 - val_accuracy: 0.6761\n",
      "Epoch 114/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6685 - accuracy: 0.7705\n",
      "Epoch 00114: val_accuracy improved from 0.69034 to 0.70170, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 124s 2s/step - loss: 0.6685 - accuracy: 0.7705 - val_loss: 1.0538 - val_accuracy: 0.7017\n",
      "Epoch 115/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6435 - accuracy: 0.7644\n",
      "Epoch 00115: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.6435 - accuracy: 0.7644 - val_loss: 1.1967 - val_accuracy: 0.6591\n",
      "Epoch 116/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7230 - accuracy: 0.7394\n",
      "Epoch 00116: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 124s 2s/step - loss: 0.7230 - accuracy: 0.7394 - val_loss: 1.0661 - val_accuracy: 0.6875\n",
      "Epoch 117/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6658 - accuracy: 0.7630\n",
      "Epoch 00117: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 125s 2s/step - loss: 0.6658 - accuracy: 0.7630 - val_loss: 1.0916 - val_accuracy: 0.6506\n",
      "Epoch 118/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6770 - accuracy: 0.7498\n",
      "Epoch 00118: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 124s 2s/step - loss: 0.6770 - accuracy: 0.7498 - val_loss: 1.0746 - val_accuracy: 0.6676\n",
      "Epoch 119/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6596 - accuracy: 0.7568\n",
      "Epoch 00119: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.6596 - accuracy: 0.7568 - val_loss: 1.1105 - val_accuracy: 0.6818\n",
      "Epoch 120/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6527 - accuracy: 0.7583\n",
      "Epoch 00120: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.6527 - accuracy: 0.7583 - val_loss: 1.0080 - val_accuracy: 0.6903\n",
      "Epoch 121/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6435 - accuracy: 0.7554\n",
      "Epoch 00121: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 124s 2s/step - loss: 0.6435 - accuracy: 0.7554 - val_loss: 1.1678 - val_accuracy: 0.6676\n",
      "Epoch 122/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6460 - accuracy: 0.7625\n",
      "Epoch 00122: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.6460 - accuracy: 0.7625 - val_loss: 1.1995 - val_accuracy: 0.6562\n",
      "Epoch 123/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6512 - accuracy: 0.7696\n",
      "Epoch 00123: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.6512 - accuracy: 0.7696 - val_loss: 1.2252 - val_accuracy: 0.6790\n",
      "Epoch 124/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6445 - accuracy: 0.7686\n",
      "Epoch 00124: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 124s 2s/step - loss: 0.6445 - accuracy: 0.7686 - val_loss: 1.1355 - val_accuracy: 0.6619\n",
      "Epoch 125/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6268 - accuracy: 0.7630\n",
      "Epoch 00125: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.6268 - accuracy: 0.7630 - val_loss: 1.1668 - val_accuracy: 0.6676\n",
      "Epoch 126/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6479 - accuracy: 0.7644\n",
      "Epoch 00126: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.6479 - accuracy: 0.7644 - val_loss: 1.2160 - val_accuracy: 0.6364\n",
      "Epoch 127/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6591 - accuracy: 0.7635\n",
      "Epoch 00127: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 124s 2s/step - loss: 0.6591 - accuracy: 0.7635 - val_loss: 1.0735 - val_accuracy: 0.6903\n",
      "Epoch 128/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6236 - accuracy: 0.7786\n",
      "Epoch 00128: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 124s 2s/step - loss: 0.6236 - accuracy: 0.7786 - val_loss: 1.2725 - val_accuracy: 0.6449\n",
      "Epoch 129/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6485 - accuracy: 0.7625\n",
      "Epoch 00129: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.6485 - accuracy: 0.7625 - val_loss: 1.0961 - val_accuracy: 0.6648\n",
      "Epoch 130/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6685 - accuracy: 0.7583\n",
      "Epoch 00130: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 124s 2s/step - loss: 0.6685 - accuracy: 0.7583 - val_loss: 1.2242 - val_accuracy: 0.6506\n",
      "Epoch 131/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6386 - accuracy: 0.7776\n",
      "Epoch 00131: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.6386 - accuracy: 0.7776 - val_loss: 1.2954 - val_accuracy: 0.6676\n",
      "Epoch 132/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6442 - accuracy: 0.7781\n",
      "Epoch 00132: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.6442 - accuracy: 0.7781 - val_loss: 1.1702 - val_accuracy: 0.6790\n",
      "Epoch 133/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6346 - accuracy: 0.7663\n",
      "Epoch 00133: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 124s 2s/step - loss: 0.6346 - accuracy: 0.7663 - val_loss: 1.1286 - val_accuracy: 0.6648\n",
      "Epoch 134/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6096 - accuracy: 0.7809\n",
      "Epoch 00134: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.6096 - accuracy: 0.7809 - val_loss: 1.0766 - val_accuracy: 0.6733\n",
      "Epoch 135/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6479 - accuracy: 0.7682\n",
      "Epoch 00135: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.6479 - accuracy: 0.7682 - val_loss: 1.2048 - val_accuracy: 0.6705\n",
      "Epoch 136/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6439 - accuracy: 0.7568\n",
      "Epoch 00136: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.6439 - accuracy: 0.7568 - val_loss: 1.1194 - val_accuracy: 0.6875\n",
      "Epoch 137/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6395 - accuracy: 0.7738\n",
      "Epoch 00137: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.6395 - accuracy: 0.7738 - val_loss: 1.1563 - val_accuracy: 0.6648\n",
      "Epoch 138/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6325 - accuracy: 0.7611\n",
      "Epoch 00138: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 125s 2s/step - loss: 0.6325 - accuracy: 0.7611 - val_loss: 1.1745 - val_accuracy: 0.6591\n",
      "Epoch 139/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6753 - accuracy: 0.7559\n",
      "Epoch 00139: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.6753 - accuracy: 0.7559 - val_loss: 1.1542 - val_accuracy: 0.6818\n",
      "Epoch 140/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6127 - accuracy: 0.7814\n",
      "Epoch 00140: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 124s 2s/step - loss: 0.6127 - accuracy: 0.7814 - val_loss: 1.1869 - val_accuracy: 0.6676\n",
      "Epoch 141/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5973 - accuracy: 0.7771\n",
      "Epoch 00141: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.5973 - accuracy: 0.7771 - val_loss: 1.1499 - val_accuracy: 0.6676\n",
      "Epoch 142/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6203 - accuracy: 0.7710\n",
      "Epoch 00142: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.6203 - accuracy: 0.7710 - val_loss: 1.1201 - val_accuracy: 0.6989\n",
      "Epoch 143/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6107 - accuracy: 0.7757\n",
      "Epoch 00143: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 124s 2s/step - loss: 0.6107 - accuracy: 0.7757 - val_loss: 1.1199 - val_accuracy: 0.6960\n",
      "Epoch 144/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6163 - accuracy: 0.7602\n",
      "Epoch 00144: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 123s 2s/step - loss: 0.6163 - accuracy: 0.7602 - val_loss: 1.0738 - val_accuracy: 0.6818\n",
      "Epoch 145/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5951 - accuracy: 0.7786\n",
      "Epoch 00145: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 126s 2s/step - loss: 0.5951 - accuracy: 0.7786 - val_loss: 1.2608 - val_accuracy: 0.6506\n",
      "Epoch 146/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6485 - accuracy: 0.7790\n",
      "Epoch 00146: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 135s 2s/step - loss: 0.6485 - accuracy: 0.7790 - val_loss: 0.9981 - val_accuracy: 0.6932\n",
      "Epoch 147/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6281 - accuracy: 0.7748\n",
      "Epoch 00147: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 183s 3s/step - loss: 0.6281 - accuracy: 0.7748 - val_loss: 1.2087 - val_accuracy: 0.7017\n",
      "Epoch 148/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5942 - accuracy: 0.7805\n",
      "Epoch 00148: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 202s 3s/step - loss: 0.5942 - accuracy: 0.7805 - val_loss: 1.0930 - val_accuracy: 0.6790\n",
      "Epoch 149/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6088 - accuracy: 0.7890\n",
      "Epoch 00149: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 196s 3s/step - loss: 0.6088 - accuracy: 0.7890 - val_loss: 1.1011 - val_accuracy: 0.6648\n",
      "Epoch 150/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5655 - accuracy: 0.7927\n",
      "Epoch 00150: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 202s 3s/step - loss: 0.5655 - accuracy: 0.7927 - val_loss: 1.2611 - val_accuracy: 0.6591\n",
      "Epoch 151/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6012 - accuracy: 0.7800\n",
      "Epoch 00151: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 190s 3s/step - loss: 0.6012 - accuracy: 0.7800 - val_loss: 1.2256 - val_accuracy: 0.6676\n",
      "Epoch 152/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5901 - accuracy: 0.8022\n",
      "Epoch 00152: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 189s 3s/step - loss: 0.5901 - accuracy: 0.8022 - val_loss: 0.8920 - val_accuracy: 0.6989\n",
      "Epoch 153/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5936 - accuracy: 0.7927\n",
      "Epoch 00153: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 198s 3s/step - loss: 0.5936 - accuracy: 0.7927 - val_loss: 1.0869 - val_accuracy: 0.6875\n",
      "Epoch 154/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5832 - accuracy: 0.7913\n",
      "Epoch 00154: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 198s 3s/step - loss: 0.5832 - accuracy: 0.7913 - val_loss: 1.0844 - val_accuracy: 0.6932\n",
      "Epoch 155/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5718 - accuracy: 0.8003\n",
      "Epoch 00155: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 195s 3s/step - loss: 0.5718 - accuracy: 0.8003 - val_loss: 1.1036 - val_accuracy: 0.6932\n",
      "Epoch 156/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6157 - accuracy: 0.7738\n",
      "Epoch 00156: val_accuracy did not improve from 0.70170\n",
      "67/67 [==============================] - 207s 3s/step - loss: 0.6157 - accuracy: 0.7738 - val_loss: 1.0808 - val_accuracy: 0.6562\n",
      "Epoch 157/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6171 - accuracy: 0.7847\n",
      "Epoch 00157: val_accuracy improved from 0.70170 to 0.70739, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 201s 3s/step - loss: 0.6171 - accuracy: 0.7847 - val_loss: 0.9646 - val_accuracy: 0.7074\n",
      "Epoch 158/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5904 - accuracy: 0.7894\n",
      "Epoch 00158: val_accuracy did not improve from 0.70739\n",
      "67/67 [==============================] - 206s 3s/step - loss: 0.5904 - accuracy: 0.7894 - val_loss: 1.1232 - val_accuracy: 0.6648\n",
      "Epoch 159/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5649 - accuracy: 0.7927\n",
      "Epoch 00159: val_accuracy did not improve from 0.70739\n",
      "67/67 [==============================] - 208s 3s/step - loss: 0.5649 - accuracy: 0.7927 - val_loss: 1.1297 - val_accuracy: 0.6960\n",
      "Epoch 160/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5599 - accuracy: 0.7979\n",
      "Epoch 00160: val_accuracy did not improve from 0.70739\n",
      "67/67 [==============================] - 208s 3s/step - loss: 0.5599 - accuracy: 0.7979 - val_loss: 1.0655 - val_accuracy: 0.7017\n",
      "Epoch 161/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5449 - accuracy: 0.8022\n",
      "Epoch 00161: val_accuracy did not improve from 0.70739\n",
      "67/67 [==============================] - 202s 3s/step - loss: 0.5449 - accuracy: 0.8022 - val_loss: 1.1322 - val_accuracy: 0.6932\n",
      "Epoch 162/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5785 - accuracy: 0.7975\n",
      "Epoch 00162: val_accuracy did not improve from 0.70739\n",
      "67/67 [==============================] - 166s 2s/step - loss: 0.5785 - accuracy: 0.7975 - val_loss: 1.1286 - val_accuracy: 0.6818\n",
      "Epoch 163/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5750 - accuracy: 0.7975\n",
      "Epoch 00163: val_accuracy did not improve from 0.70739\n",
      "67/67 [==============================] - 200s 3s/step - loss: 0.5750 - accuracy: 0.7975 - val_loss: 1.0474 - val_accuracy: 0.6733\n",
      "Epoch 164/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5916 - accuracy: 0.7682\n",
      "Epoch 00164: val_accuracy did not improve from 0.70739\n",
      "67/67 [==============================] - 195s 3s/step - loss: 0.5916 - accuracy: 0.7682 - val_loss: 1.2289 - val_accuracy: 0.6705\n",
      "Epoch 165/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5866 - accuracy: 0.7800\n",
      "Epoch 00165: val_accuracy did not improve from 0.70739\n",
      "67/67 [==============================] - 194s 3s/step - loss: 0.5866 - accuracy: 0.7800 - val_loss: 1.3010 - val_accuracy: 0.7045\n",
      "Epoch 166/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5892 - accuracy: 0.7908\n",
      "Epoch 00166: val_accuracy did not improve from 0.70739\n",
      "67/67 [==============================] - 197s 3s/step - loss: 0.5892 - accuracy: 0.7908 - val_loss: 1.1650 - val_accuracy: 0.6960\n",
      "Epoch 167/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5468 - accuracy: 0.7937\n",
      "Epoch 00167: val_accuracy did not improve from 0.70739\n",
      "67/67 [==============================] - 197s 3s/step - loss: 0.5468 - accuracy: 0.7937 - val_loss: 1.0811 - val_accuracy: 0.6989\n",
      "Epoch 168/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6149 - accuracy: 0.7885\n",
      "Epoch 00168: val_accuracy did not improve from 0.70739\n",
      "67/67 [==============================] - 205s 3s/step - loss: 0.6149 - accuracy: 0.7885 - val_loss: 1.0988 - val_accuracy: 0.6761\n",
      "Epoch 169/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5352 - accuracy: 0.7960\n",
      "Epoch 00169: val_accuracy did not improve from 0.70739\n",
      "67/67 [==============================] - 203s 3s/step - loss: 0.5352 - accuracy: 0.7960 - val_loss: 1.1247 - val_accuracy: 0.6307\n",
      "Epoch 170/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5957 - accuracy: 0.7823\n",
      "Epoch 00170: val_accuracy did not improve from 0.70739\n",
      "67/67 [==============================] - 195s 3s/step - loss: 0.5957 - accuracy: 0.7823 - val_loss: 0.9704 - val_accuracy: 0.6932\n",
      "Epoch 171/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5957 - accuracy: 0.7866\n",
      "Epoch 00171: val_accuracy did not improve from 0.70739\n",
      "67/67 [==============================] - 195s 3s/step - loss: 0.5957 - accuracy: 0.7866 - val_loss: 1.0091 - val_accuracy: 0.6989\n",
      "Epoch 172/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6037 - accuracy: 0.7800\n",
      "Epoch 00172: val_accuracy did not improve from 0.70739\n",
      "67/67 [==============================] - 197s 3s/step - loss: 0.6037 - accuracy: 0.7800 - val_loss: 1.1357 - val_accuracy: 0.6790\n",
      "Epoch 173/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5698 - accuracy: 0.8045\n",
      "Epoch 00173: val_accuracy did not improve from 0.70739\n",
      "67/67 [==============================] - 194s 3s/step - loss: 0.5698 - accuracy: 0.8045 - val_loss: 1.2031 - val_accuracy: 0.6733\n",
      "Epoch 174/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5555 - accuracy: 0.7923\n",
      "Epoch 00174: val_accuracy did not improve from 0.70739\n",
      "67/67 [==============================] - 189s 3s/step - loss: 0.5555 - accuracy: 0.7923 - val_loss: 1.1360 - val_accuracy: 0.6903\n",
      "Epoch 175/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5599 - accuracy: 0.8059\n",
      "Epoch 00175: val_accuracy improved from 0.70739 to 0.71875, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 201s 3s/step - loss: 0.5599 - accuracy: 0.8059 - val_loss: 1.0291 - val_accuracy: 0.7188\n",
      "Epoch 176/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5981 - accuracy: 0.7705\n",
      "Epoch 00176: val_accuracy did not improve from 0.71875\n",
      "67/67 [==============================] - 203s 3s/step - loss: 0.5981 - accuracy: 0.7705 - val_loss: 1.1283 - val_accuracy: 0.6932\n",
      "Epoch 177/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5577 - accuracy: 0.7965\n",
      "Epoch 00177: val_accuracy did not improve from 0.71875\n",
      "67/67 [==============================] - 198s 3s/step - loss: 0.5577 - accuracy: 0.7965 - val_loss: 1.1142 - val_accuracy: 0.6932\n",
      "Epoch 178/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5083 - accuracy: 0.8239\n",
      "Epoch 00178: val_accuracy did not improve from 0.71875\n",
      "67/67 [==============================] - 202s 3s/step - loss: 0.5083 - accuracy: 0.8239 - val_loss: 1.1986 - val_accuracy: 0.6818\n",
      "Epoch 179/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5614 - accuracy: 0.7965\n",
      "Epoch 00179: val_accuracy did not improve from 0.71875\n",
      "67/67 [==============================] - 196s 3s/step - loss: 0.5614 - accuracy: 0.7965 - val_loss: 1.2118 - val_accuracy: 0.6960\n",
      "Epoch 180/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5605 - accuracy: 0.8140\n",
      "Epoch 00180: val_accuracy did not improve from 0.71875\n",
      "67/67 [==============================] - 196s 3s/step - loss: 0.5605 - accuracy: 0.8140 - val_loss: 1.0943 - val_accuracy: 0.6676\n",
      "Epoch 181/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5284 - accuracy: 0.8078\n",
      "Epoch 00181: val_accuracy did not improve from 0.71875\n",
      "67/67 [==============================] - 200s 3s/step - loss: 0.5284 - accuracy: 0.8078 - val_loss: 1.1050 - val_accuracy: 0.6932\n",
      "Epoch 182/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5711 - accuracy: 0.7941\n",
      "Epoch 00182: val_accuracy did not improve from 0.71875\n",
      "67/67 [==============================] - 198s 3s/step - loss: 0.5711 - accuracy: 0.7941 - val_loss: 1.0734 - val_accuracy: 0.7017\n",
      "Epoch 183/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5152 - accuracy: 0.8182\n",
      "Epoch 00183: val_accuracy did not improve from 0.71875\n",
      "67/67 [==============================] - 199s 3s/step - loss: 0.5152 - accuracy: 0.8182 - val_loss: 1.2899 - val_accuracy: 0.6960\n",
      "Epoch 184/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5715 - accuracy: 0.8017\n",
      "Epoch 00184: val_accuracy did not improve from 0.71875\n",
      "67/67 [==============================] - 191s 3s/step - loss: 0.5715 - accuracy: 0.8017 - val_loss: 1.2366 - val_accuracy: 0.6818\n",
      "Epoch 185/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5071 - accuracy: 0.8173\n",
      "Epoch 00185: val_accuracy did not improve from 0.71875\n",
      "67/67 [==============================] - 196s 3s/step - loss: 0.5071 - accuracy: 0.8173 - val_loss: 1.2912 - val_accuracy: 0.6989\n",
      "Epoch 186/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5656 - accuracy: 0.8026\n",
      "Epoch 00186: val_accuracy did not improve from 0.71875\n",
      "67/67 [==============================] - 196s 3s/step - loss: 0.5656 - accuracy: 0.8026 - val_loss: 1.1918 - val_accuracy: 0.6676\n",
      "Epoch 187/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.4939 - accuracy: 0.8211\n",
      "Epoch 00187: val_accuracy did not improve from 0.71875\n",
      "67/67 [==============================] - 198s 3s/step - loss: 0.4939 - accuracy: 0.8211 - val_loss: 1.3112 - val_accuracy: 0.6648\n",
      "Epoch 188/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5502 - accuracy: 0.7866\n",
      "Epoch 00188: val_accuracy improved from 0.71875 to 0.72159, saving model to garbage_model.h5\n",
      "67/67 [==============================] - 201s 3s/step - loss: 0.5502 - accuracy: 0.7866 - val_loss: 1.1637 - val_accuracy: 0.7216\n",
      "Epoch 189/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5163 - accuracy: 0.8008\n",
      "Epoch 00189: val_accuracy did not improve from 0.72159\n",
      "67/67 [==============================] - 207s 3s/step - loss: 0.5163 - accuracy: 0.8008 - val_loss: 0.9984 - val_accuracy: 0.6818\n",
      "Epoch 190/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5002 - accuracy: 0.8097\n",
      "Epoch 00190: val_accuracy did not improve from 0.72159\n",
      "67/67 [==============================] - 199s 3s/step - loss: 0.5002 - accuracy: 0.8097 - val_loss: 1.1852 - val_accuracy: 0.6903\n",
      "Epoch 191/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5263 - accuracy: 0.8159\n",
      "Epoch 00191: val_accuracy did not improve from 0.72159\n",
      "67/67 [==============================] - 140s 2s/step - loss: 0.5263 - accuracy: 0.8159 - val_loss: 1.3147 - val_accuracy: 0.6932\n",
      "Epoch 192/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5486 - accuracy: 0.8050\n",
      "Epoch 00192: val_accuracy did not improve from 0.72159\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.5486 - accuracy: 0.8050 - val_loss: 1.1980 - val_accuracy: 0.6705\n",
      "Epoch 193/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5098 - accuracy: 0.8196\n",
      "Epoch 00193: val_accuracy did not improve from 0.72159\n",
      "67/67 [==============================] - 119s 2s/step - loss: 0.5098 - accuracy: 0.8196 - val_loss: 1.2142 - val_accuracy: 0.6364\n",
      "Epoch 194/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5077 - accuracy: 0.8182\n",
      "Epoch 00194: val_accuracy did not improve from 0.72159\n",
      "67/67 [==============================] - 122s 2s/step - loss: 0.5077 - accuracy: 0.8182 - val_loss: 1.1145 - val_accuracy: 0.6705\n",
      "Epoch 195/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5047 - accuracy: 0.8248\n",
      "Epoch 00195: val_accuracy did not improve from 0.72159\n",
      "67/67 [==============================] - 118s 2s/step - loss: 0.5047 - accuracy: 0.8248 - val_loss: 1.1055 - val_accuracy: 0.6818\n",
      "Epoch 196/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5104 - accuracy: 0.8130\n",
      "Epoch 00196: val_accuracy did not improve from 0.72159\n",
      "67/67 [==============================] - 112s 2s/step - loss: 0.5104 - accuracy: 0.8130 - val_loss: 1.0575 - val_accuracy: 0.6932\n",
      "Epoch 197/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5145 - accuracy: 0.8126\n",
      "Epoch 00197: val_accuracy did not improve from 0.72159\n",
      "67/67 [==============================] - 114s 2s/step - loss: 0.5145 - accuracy: 0.8126 - val_loss: 1.2865 - val_accuracy: 0.6619\n",
      "Epoch 198/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.4712 - accuracy: 0.8272\n",
      "Epoch 00198: val_accuracy did not improve from 0.72159\n",
      "67/67 [==============================] - 113s 2s/step - loss: 0.4712 - accuracy: 0.8272 - val_loss: 1.1922 - val_accuracy: 0.6989\n",
      "Epoch 199/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5057 - accuracy: 0.8149\n",
      "Epoch 00199: val_accuracy did not improve from 0.72159\n",
      "67/67 [==============================] - 125s 2s/step - loss: 0.5057 - accuracy: 0.8149 - val_loss: 1.1912 - val_accuracy: 0.6960\n",
      "Epoch 200/200\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5357 - accuracy: 0.8163\n",
      "Epoch 00200: val_accuracy did not improve from 0.72159\n",
      "67/67 [==============================] - 144s 2s/step - loss: 0.5357 - accuracy: 0.8163 - val_loss: 1.1688 - val_accuracy: 0.6932\n"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(train_generator, epochs=200, steps_per_epoch=step_size_train, validation_data=test_generator,\n",
    "                           validation_steps=step_size_test, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-3bb9d91880ad>:1: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "[1.1641509532928467, 0.6875]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate_generator(test_generator, steps=step_size_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_path = /tmp/1\n",
      "\n",
      "WARNING:tensorflow:From /home/febriyanto/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /tmp/1/assets\n",
      "\n",
      "Saved model:\n",
      "total 176\n",
      "drwxr-xr-x 2 febriyanto febriyanto   4096 Jun 11 21:28 assets\n",
      "-rw-r--r-- 1 febriyanto febriyanto 169810 Jun 11 21:28 saved_model.pb\n",
      "drwxr-xr-x 2 febriyanto febriyanto   4096 Jun 11 21:28 variables\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "MODEL_DIR = tempfile.gettempdir()\n",
    "version = 1\n",
    "export_path = os.path.join(MODEL_DIR, str(version))\n",
    "print('export_path = {}\\n'.format(export_path))\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    export_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")\n",
    "\n",
    "print('\\nSaved model:')\n",
    "!ls -l {export_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11371456"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('garbage_model.h5')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()#saving converted model in \"converted_model.tflite\" file\n",
    "open(\"converted_garbage_model1.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2850080"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = tf.keras.models.load_model('garbage_model.h5')\n",
    "converter1 = tf.lite.TFLiteConverter.from_keras_model(model1)\n",
    "converter1.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter1.convert()#saving converted model in \"converted_quant_model.tflite\" file\n",
    "open(\"converted_garbage_quant_model1.tflite\", \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-13 20:27:04--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "wget: Cannot read /home/febriyanto/.netrc (Permission denied).\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.194.128, 2404:6800:4003:c03::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.194.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 87910968 (84M) [application/x-hdf]\n",
      "Saving to: /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\n",
      "/tmp/inception_v3_w 100%[===================>]  83,84M  12,0MB/s    in 7,1s    \n",
      "\n",
      "2020-06-13 20:27:11 (11,8 MB/s) - /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 saved [87910968/87910968]\n",
      "\n",
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights = None)\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False\n",
    "  \n",
    "# pre_trained_model.summary()\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
<<<<<<< HEAD
   "metadata": {},
=======
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
>>>>>>> 27485c376428475b7430ad8d66219369a09106c2
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         38536192    flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1024)         0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 6)            6150        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 47,517,606\n",
      "Trainable params: 38,542,342\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (6, activation='softmax')(x)           \n",
    "\n",
    "model = Model( pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model_path='garbage_model-pretrained.h5'\n",
    "checkpoint1 = ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint1]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 1.8456 - accuracy: 0.6280\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68466, saving model to garbage_model-pretrained.h5\n",
      "67/67 [==============================] - 60s 902ms/step - loss: 1.8456 - accuracy: 0.6280 - val_loss: 0.8169 - val_accuracy: 0.6847\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5908 - accuracy: 0.7932\n",
      "Epoch 00002: val_accuracy improved from 0.68466 to 0.69886, saving model to garbage_model-pretrained.h5\n",
      "67/67 [==============================] - 67s 1s/step - loss: 0.5908 - accuracy: 0.7932 - val_loss: 0.8556 - val_accuracy: 0.6989\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.5414 - accuracy: 0.8074\n",
      "Epoch 00003: val_accuracy improved from 0.69886 to 0.74148, saving model to garbage_model-pretrained.h5\n",
      "67/67 [==============================] - 52s 783ms/step - loss: 0.5414 - accuracy: 0.8074 - val_loss: 0.7201 - val_accuracy: 0.7415\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.4206 - accuracy: 0.8493\n",
      "Epoch 00004: val_accuracy improved from 0.74148 to 0.78977, saving model to garbage_model-pretrained.h5\n",
      "67/67 [==============================] - 62s 927ms/step - loss: 0.4206 - accuracy: 0.8493 - val_loss: 0.5877 - val_accuracy: 0.7898\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.3655 - accuracy: 0.8706\n",
      "Epoch 00005: val_accuracy did not improve from 0.78977\n",
      "67/67 [==============================] - 60s 892ms/step - loss: 0.3655 - accuracy: 0.8706 - val_loss: 0.6928 - val_accuracy: 0.7898\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.3350 - accuracy: 0.8895\n",
      "Epoch 00006: val_accuracy did not improve from 0.78977\n",
      "67/67 [==============================] - 48s 711ms/step - loss: 0.3350 - accuracy: 0.8895 - val_loss: 0.6864 - val_accuracy: 0.7699\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.3362 - accuracy: 0.8810\n",
      "Epoch 00007: val_accuracy improved from 0.78977 to 0.83239, saving model to garbage_model-pretrained.h5\n",
      "67/67 [==============================] - 48s 718ms/step - loss: 0.3362 - accuracy: 0.8810 - val_loss: 0.5672 - val_accuracy: 0.8324\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2607 - accuracy: 0.9089\n",
      "Epoch 00008: val_accuracy did not improve from 0.83239\n",
      "67/67 [==============================] - 47s 707ms/step - loss: 0.2607 - accuracy: 0.9089 - val_loss: 0.7292 - val_accuracy: 0.7642\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2762 - accuracy: 0.8961\n",
      "Epoch 00009: val_accuracy did not improve from 0.83239\n",
      "67/67 [==============================] - 47s 698ms/step - loss: 0.2762 - accuracy: 0.8961 - val_loss: 0.6328 - val_accuracy: 0.7926\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2072 - accuracy: 0.9249\n",
      "Epoch 00010: val_accuracy did not improve from 0.83239\n",
      "67/67 [==============================] - 47s 702ms/step - loss: 0.2072 - accuracy: 0.9249 - val_loss: 0.6717 - val_accuracy: 0.8011\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2907 - accuracy: 0.9032\n",
      "Epoch 00011: val_accuracy did not improve from 0.83239\n",
      "67/67 [==============================] - 48s 715ms/step - loss: 0.2907 - accuracy: 0.9032 - val_loss: 0.7447 - val_accuracy: 0.7955\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2274 - accuracy: 0.9212\n",
      "Epoch 00012: val_accuracy did not improve from 0.83239\n",
      "67/67 [==============================] - 47s 708ms/step - loss: 0.2274 - accuracy: 0.9212 - val_loss: 0.8152 - val_accuracy: 0.7727\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2342 - accuracy: 0.9254\n",
      "Epoch 00013: val_accuracy did not improve from 0.83239\n",
      "67/67 [==============================] - 49s 726ms/step - loss: 0.2342 - accuracy: 0.9254 - val_loss: 0.6963 - val_accuracy: 0.7869\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.2217 - accuracy: 0.9178\n",
      "Epoch 00014: val_accuracy did not improve from 0.83239\n",
      "67/67 [==============================] - 48s 713ms/step - loss: 0.2217 - accuracy: 0.9178 - val_loss: 0.6386 - val_accuracy: 0.7926\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1585 - accuracy: 0.9433\n",
      "Epoch 00015: val_accuracy did not improve from 0.83239\n",
      "67/67 [==============================] - 47s 704ms/step - loss: 0.1585 - accuracy: 0.9433 - val_loss: 0.6451 - val_accuracy: 0.8182\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1546 - accuracy: 0.9400\n",
      "Epoch 00016: val_accuracy did not improve from 0.83239\n",
      "67/67 [==============================] - 48s 710ms/step - loss: 0.1546 - accuracy: 0.9400 - val_loss: 0.8015 - val_accuracy: 0.7812\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1426 - accuracy: 0.9500\n",
      "Epoch 00017: val_accuracy did not improve from 0.83239\n",
      "67/67 [==============================] - 48s 712ms/step - loss: 0.1426 - accuracy: 0.9500 - val_loss: 0.7065 - val_accuracy: 0.7955\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1692 - accuracy: 0.9419\n",
      "Epoch 00018: val_accuracy did not improve from 0.83239\n",
      "67/67 [==============================] - 47s 705ms/step - loss: 0.1692 - accuracy: 0.9419 - val_loss: 0.6460 - val_accuracy: 0.8182\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1418 - accuracy: 0.9504\n",
      "Epoch 00019: val_accuracy did not improve from 0.83239\n",
      "67/67 [==============================] - 48s 710ms/step - loss: 0.1418 - accuracy: 0.9504 - val_loss: 0.7051 - val_accuracy: 0.8125\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.1532 - accuracy: 0.9443\n",
      "Epoch 00020: val_accuracy did not improve from 0.83239\n",
      "67/67 [==============================] - 47s 706ms/step - loss: 0.1532 - accuracy: 0.9443 - val_loss: 0.8541 - val_accuracy: 0.8040\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data = test_generator,\n",
    "            steps_per_epoch = step_size_train,\n",
    "            epochs = 20,\n",
    "            validation_steps = step_size_test,\n",
    "            verbose = 1,\n",
    "            callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO2dd5gU1dKH3yIJSE6iIEExEASEBVFAMSGYMyCogIAJUa8JzB/mgBm5YOAqKhhQQUS5iigoiixIUDKIl2URyUHi7tb3R80uw7phdnfC7my9zzPP9HSfPl3dM/Pr03Xq1BFVxXEcx4lfSsTaAMdxHCeyuNA7juPEOS70juM4cY4LveM4TpzjQu84jhPnuNA7juPEOS70xRARKSkiO0WkXjjLxhIRaSQiYY8VFpGzRGR10OelItIxlLL5ONbrInJvfvd3nOwoFWsDnNwRkZ1BH8sDe4HUwOfrVfXdvNSnqqlAhXCXLQ6o6nHhqEdE+gG9VLVTUN39wlG342TGhb4IoKoZQhtoMfZT1a+zKy8ipVQ1JRq2OU5u+O8x9rjrJg4QkUdF5H0RGSsiO4BeInKyiPwkIltFZJ2IvCQipQPlS4mIikiDwOd3Atu/EJEdIvKjiDTMa9nA9q4iskxEtonIyyLyg4j0zsbuUGy8XkRWiMgWEXkpaN+SIvK8iGwSkZVAlxyuz/0iMi7TuuEi8lxguZ+ILA6cz8pAazu7upJEpFNgubyIjAnY9hvQOovjrgrU+5uIXBhYfwLwCtAx4BbbGHRtHw7a/4bAuW8SkU9F5PBQrk1ernO6PSLytYhsFpE/ReTuoOM8ELgm20UkUUSOyMpNJiLfp3/Pges5PXCczcD9InKMiEwLnMvGwHWrHLR//cA5bghsf1FEygZsbhxU7nAR2SUi1bM7XycLVNVfRegFrAbOyrTuUWAfcAF28y4HtAFOwp7ajgKWAQMD5UsBCjQIfH4H2AgkAKWB94F38lG2FrADuCiw7V/AfqB3NucSio0TgMpAA2Bz+rkDA4HfgLpAdWC6/ZyzPM5RwE7g0KC6/wISAp8vCJQR4AxgN9A8sO0sYHVQXUlAp8Dys8C3QFWgPrAoU9krgcMD38lVARsOC2zrB3ybyc53gIcDy50DNrYEygKvAt+Ecm3yeJ0rA+uBW4FDgEpA28C2IcB84JjAObQEqgGNMl9r4Pv07zlwbinAjUBJ7Pd4LHAmUCbwO/kBeDbofH4NXM9DA+XbB7aNAh4LOs4dwCex/h8WtVfMDfBXHr+w7IX+m1z2uxP4MLCclXj/O6jshcCv+SjbF5gRtE2AdWQj9CHa2C5o+8fAnYHl6ZgLK33buZnFJ1PdPwFXBZa7AstyKDsJuDmwnJPQ/y/4uwBuCi6bRb2/AucFlnMT+reAx4O2VcL6Zermdm3yeJ2vBhKzKbcy3d5M60MR+lW52HA5MDuw3BH4EyiZRbn2wO+ABD7PAy4N9/8q3l/uuokf1gR/EJHjReTzwKP4dmAoUCOH/f8MWt5Fzh2w2ZU9ItgOtX9mUnaVhGhjSMcC/sjBXoD3gB6B5auAjA5sETlfRGYFXBdbsdZ0TtcqncNzskFEeovI/ID7YStwfIj1gp1fRn2quh3YAtQJKhPSd5bLdT4SWJGNDUdiYp8fMv8ea4vIByKyNmDDfzLZsFqt4/8gVPUH7Omgg4g0A+oBn+fTpmKLC338kDm0cCTWgmykqpWAB7EWdiRZh7U4ARAR4WBhykxBbFyHCUQ6uYV/vg+cJSJ1MdfSewEbywEfAU9gbpUqwH9DtOPP7GwQkaOAEZj7onqg3iVB9eYWCpqMuYPS66uIuYjWhmBXZnK6zmuAo7PZL7ttfwdsKh+0rnamMpnP7yksWuyEgA29M9lQX0RKZmPH20Av7OnjA1Xdm005Jxtc6OOXisA24O9AZ9b1UTjmJKCViFwgIqUwv2/NCNn4AXCbiNQJdMzdk1NhVV2PuRdGA0tVdXlg0yGY33gDkCoi52O+5FBtuFdEqoiNMxgYtK0CJnYbsHteP6xFn856oG5wp2gmxgLXiUhzETkEuxHNUNVsn5ByIKfrPBGoJyIDRaSMiFQSkbaBba8Dj4rI0WK0FJFq2A3uT6zTv6SIDCDoppSDDX8D20TkSMx9lM6PwCbgcbEO7nIi0j5o+xjM1XMVJvpOHnGhj1/uAK7FOkdHYi3aiBIQ027Ac9gf92jgF6wlF24bRwBTgYXAbKxVnhvvYT7394Js3grcDnyCdWhejt2wQuEh7MliNfAFQSKkqguAl4CfA2WOB2YF7fsVsBxYLyLBLpj0/b/EXCyfBPavB/QM0a7MZHudVXUbcDZwGdb5uww4LbD5GeBT7DpvxzpGywZccv2Be7GO+UaZzi0rHgLaYjecicD4IBtSgPOBxljr/n/Y95C+fTX2Pe9T1Zl5PHeHAx0cjhN2Ao/iycDlqjoj1vY4RRcReRvr4H041rYURXzAlBNWRKQL9ii+BwvPS8FatY6TLwL9HRcBJ8TalqKKu26ccNMBWIU90ncBLvbOMye/iMgTWCz/46r6v1jbU1Rx143jOE6c4y16x3GcOKfQ+ehr1KihDRo0iLUZjuM4RYo5c+ZsVNUsw5kLndA3aNCAxMTEWJvhOI5TpBCRbEeHu+vGcRwnznGhdxzHiXNc6B3HceIcF3rHcZw4x4XecRwnzglJ6EWki4gsDUxbNjiL7fVFZKqILBCRbwOpYNO3pYrIvMBrYjiNdxzHcXIn1/DKQGKq4ViGuyRgtohMVNVFQcWeBd5W1bdE5AwsperVgW27VbVlmO12HMdxQiSUOPq2wApVXQUgNsnyRdj8mOk0wVK9AkzDUps6juNEj/XrQRVqZ54DJQps2gSTJsGuXdC+PTRtCiWzm0cl+oQi9HU4eFqwJGyi4WDmY/msXwQuASqKSHVV3QSUFZFELIvhk6rqNwHHccLD3r0wYQKMHg3//S+kpUHbtnDRRXDhhSa4EqGJ1davh08+gfHjYdo0SA2aCbFyZTjlFOjQATp2hDZtoGzZyNgRAqEIfVZXKXMmtDuBV0SkNzZp81pM2AHqqWpyINXoNyKyUFUPmocyMEPNAIB69XKbEc5xnGKNKvzyi4n7u+/Cli1Qty4MGQLly5vw33efvY46ygT/ootMdEsVMBlAUhJ8/LGJ+4wZZssxx8Bdd8Hll0PVqvDDD/D99/b64gvbr0wZSEgwGzp0sFZ/tWoFvxYhkmv2ShE5GZuZ/pzA5yEAqvpENuUrAEtUtW4W2/4DTFLVbGcDSkhIUE+B4DjOP9iwwYR99GhYsAAOOQQuuQT69IEzzzzYVZKcbK6UCRNg6lRr+VetCuedZ6J/zjlQsWJox/39dxP2jz6CWYGJtJo1g8sus1ezZtk/NWzaBDNnmujPmAGJibB/v21r2vSA8HfoAPXrF+jpQ0TmqGpClttCEPpS2PRiZ2It9dnAVar6W1CZGsBmVU0TkceAVFV9UESqArtUdW+gzI/ARZk6cg/Chd5xiii7d1vrunZtKBGmyO2UFGsVjx5twr1/v7lB+vSB7t1NvHNj506YMgUmTrQ6Nm+2FvYZZxxw8RxxxMH7LF1qwj5+vD09ALRqdUDcjzsuf+ezezfMnn2gxf/DD7B9u22rU8fsGT48X1UXSOgDFZwLvACUBN5U1cdEZCiQqKoTReRyLNJGMdfNzQFxPwWbozINC+V8QVXfyOlYLvSOUwRZssRa1cnJJqL160PDhtCgwYH39OVatXJvuS5ebOL+9tvmC69VC3r1MoFv1iz/dqakmLhOnGit/ZUBL3JCgolsSooJ/G+Bdmy7dgfEvWHD/B83O1JT7Vjpwl+5MowYka+qCiz00cSF3nGKGL/+aiIvYn7ytWth9WpzeaxeDRs3Hly+XLkDwh98I6hf/4DvfdYs86efd56J+7nnQunS4bVbFRYtOiD6s2bZOXTsaP72Sy4x338RwYXecZzIMG8enHWW+cu/+SZrl8bOnSb46a/0G0D6+5YtB5dv2hT69oWePeGwwyJ+ChmsX28up5pZpnQv9OQk9IUuH73jOEWExETo3BkqVDCRb9Qo63IVKpi7JTuXy7ZtB24CdepA69aRC4nMiWjeVKKMC73jOHnnp58scqVaNYshL8iscJUrQ4sW9nIigic1cxwnb3z/PZx9trk4pk8vmMg7UcGF3nGc0Pn2W2vJ16kD330HRx4Za4ucEHChdxwnNL76yqJfGjQwwa9TJ9YWOSHiQu84Tu5MngwXXGDD/b/9NjaJw5x840LvOE7OTJgAF19sYY/ffFNkww+LMy70jhMPqFrCrR07wlvvRx/Z4KETT7ScMdWrh7d+Jyp4eKXjgA3queoqaNIEHnusUOUSP4jUVIs3X7TIXosXH3jfudNGj556qvnSzz3XBjDlNyZ97Fi4+mo46STLN1OpUlhPxYkePjLWcfbtg/PPh6+/tpZxly4wbpzFd8fSphUrDhbyRYss2daePQfKHXEENG5sN6jjj7ebwOTJB3K1NGx4QPQ7dbI0vqHw9tuWeqBjR0sEVqFCuM/QCTOeAsFxsiMtzZJljR0Lb75p2RFvvtk6HT/7DI4+Ojp2pKbCyJHmHlm8GJYvtwRb6TRoYGKeLurpwl6lStb1/fGHtcInT7Y6d+2yiS86dTog/Nmd2xtvQP/+lr9mwoTQbw5OTHGhd5ysUIXbb4cXX4Qnn4R77rH1335r2QrB0tR26hRZO1asgGuvtbzljRpZqoBgUT/uODj00PzXv2eP5UKfPNley5bZ+mOPPSD6p55q+WpGjICbbrKnmo8/tgRkTpEgJ6FHVQvVq3Xr1uo4UeGJJ1RB9bbbVNPSDt62YoVq48aqpUqpjhwZmeOnpamOGKFavrxq5cqq77zzTzsiwfLlqi+9pNqli+ohh9g1OPRQ1U6dbPmCC1T37Im8HU5YwdLGZ6mrMRf2zC8XeicqvPmm/fx79FBNTc26zNatql27WrlbblHdvz98x09KUj3nHKv77LNV16wJX915YedO1UmTVG+6SfWYY1R791bduzc2tjgFIiehd9eNU/z47DPLNX7mmbZcpkz2ZVNT4e674bnnLFPj++9n7xcPlXHjzD2yZw88+yzceGNssjU6cUVOrhuPo3eKFzNnwpVX2rRw48fnLPJgYZbDhsHrr1uWxnbtrKM0P2zaBN26QY8e5nefN88E30XeiTAu9E7x4bffLIzyyCPh88/zFjJ43XUWfrlpk8WVT52at2NPnmydrJ98YnH6M2ZYZ6jjRAEXeqfwEEk34v/+Z1kXy5aF//43f8P4Tz0Vfv7ZYtfPOQdefTX3fXbsgAEDbEq8GjVs/3vvtWnyHCdKuNA7hYNVqyxWvF07G6ATTtHftMmEeedO+PLLguVPb9jQ3D9du1q8/U03Wex9VsyYYZNpvP66+fkTE6Fly/wf23HyiQu9E3vWrrV5R3futHk7L7jAppP7+GMb0FQQ/v7bWtO//26TQDdvXnB7K1WCTz+Fu+6yuPOuXWHz5gPb9+yxbaedZv736dPhqacsTt1xYoALvRNbNm60aJaNG2HKFBvMM3q0if5ll5kwjxtn0S95Zf9+uOIKmD3b6jj11PDZXbIkPP202TpjhvntlyyBX36BhASLphkwAObPhw4dwndcx8kHIQm9iHQRkaUiskJEBmexvb6ITBWRBSLyrYjUDdp2rYgsD7yuDafxThFn+3ZrDa9aZWGOCQmWlKt3b8vr8u675sLp0cNGiL711sFpAXIiLc06UL/4Av79b0uzGwl697bUvdu2Qdu29tq82Tpf//1vzxHjFA6yC7BPfwElgZXAUUAZYD7QJFOZD4FrA8tnAGMCy9WAVYH3qoHlqjkdzwdMFRN27VI97TQbeTppUvblUlNVP/xQtUULG1zUsKHqqFG5D+q56y4r/8gjYTU7W1avVj3lFNWePVU3bozOMR0nCAoyMhY4GZgS9HkIMCRTmd+AuoFlAbYHlnsAI4PKjQR65HQ8F/piwN69quedpyqi+t57oe2TlqY6caJqmzb2sz3ySNVXXlHdvfufZZ991srcfHN0Ugo4TiEgJ6EPxXVTB1gT9DkpsC6Y+UAgCxSXABVFpHqI+yIiA0QkUUQSN2zYEIJJTpElNRWuucbi2EeMMLdMKIhYJ+2sWRY5U68eDBxoUTDPPWedrgBjxsCdd5pv/sUXfTCS4xCajz6rf0rm2Lc7gdNE5BfgNGAtkBLivqjqKFVNUNWEmj5NWfyiauGI779vUSjXX5/3OkQsVHLGDPONN24Md9xhgj9oEPTtC2ecYYJfWCcPcZwoE4rQJwFHBn2uCyQHF1DVZFW9VFVPBO4LrNsWyr5OMUHV0gCPGmUDhu6+u2D1icDpp5vYf/+9hWO+/DKccIKNPvVQRsfJIBShnw0cIyINRaQM0B2YGFxARGqISHpdQ4A3A8tTgM4iUlVEqgKdA+uc4saTT8Izz1iL/tFHw1t3+/YWXbNokeWS9ynvHOcgchV6VU0BBmICvRj4QFV/E5GhInJhoFgnYKmILAMOAx4L7LsZeAS7WcwGhgbWOcWJV1+1VnyvXtbqjpTfvHFjF3nHyQJPU+wcYNs2ywUTTrfHO+/YBNMXXggffWRx8o7jhB1PU+zkTFoaPP881Kplyb6uusrSD+zaVbB6J0ywAUWnn24dsC7yjhMTPIVecWf9ehPjL7+0FL61a1tn5tixNil0166WiuC88/LmFpk61fK+JySY4JctG7FTcBwnZ7xFX5yZMsWyK06bBq+8Ykm/XnsN/vzThLp3b/jhB2vh16xp7pe33oItW3Kud9YsuOgiy7c+eTJUrBiV03EcJ2tc6Isje/da7HmXLpYjffZsS7mb3klaqpTFog8fbpklZ8ywaJl580z8a9WyWPZRo+Cvvw6ue+FCewqoXdvyvlerFvXTcxznYLwztrixdKm10OfOtblKhw2DcuVC21fVcqqPH28dqytXQokSlhXyssvgxBPh8sttoNL33xcs77vjOHkip85YF/rigqql1L3lFvOXv/FGwTI6qsKCBSb648dbDDtA9er2BNC4cXjsdhwnJFzoiztbt1q6gQ8+gE6dLD1A3bq57pYnFi+2maG6dLHRqY7jRJWchN6jbuKdmTPNVZOUBI8/bqkHIpEDpnFjb8U7TiHFO2PjldRUeOQR85+XKGE+8yFDPNGX4xRDvEUfj6xZY+kGpk+31vyrr0LlyrG2ynGcGOFCH298/DH062fzpb71lqUf8JzsjlOscddNvLB3L9xwg4U5Nmpkk1Rfc42LvOM4LvRxwbp1Fk0zciTcdZf54xs1irVVjuMUEtx1U9SZPdvi4bduhQ8/tAFLjuM4QXiLvijzzjvQsSOUKWNhlC7yjuNkgQt9USQ11Vw0V18NJ59srfoWLWJtleM4hRR33RQ1tmyB7t0tYdjNN1seec/z7jhODrjQFyUWL7b0v6tXW+bI/v1jbZHjOEUAF/qiwqRJNvipXDn45hvo0CHWFjmOU0RwH31hR9Vy1Fx4IRxzjPnjXeQdx8kD3qIvzOzaBX372nyr3btbauHy5WNtleM4RQxv0RdW/vc/a7l/8AE88QS8956LvOM4+SIkoReRLiKyVERWiMjgLLbXE5FpIvKLiCwQkXMD6xuIyG4RmRd4/TvcJxCXzJhhk2qvXAmffQaDB3sqA8dx8k2urhsRKQkMB84GkoDZIjJRVRcFFbsf+EBVR4hIE2Ay0CCwbaWqtgyv2XHMyJEwcCAcdRRMmADHHx9rixzHKeKE0qJvC6xQ1VWqug8YB1yUqYwClQLLlYHk8JlYTFC1af5uuAHOOgtmzXKRdxwnLIQi9HWANUGfkwLrgnkY6CUiSVhr/pagbQ0DLp3vRKRjVgcQkQEikigiiRs2bAjd+nji/ffhlVdg0CALpaxSJdYWOY4TJ4Qi9Fk5hzNPNNsD+I+q1gXOBcaISAlgHVBPVU8E/gW8JyKVMu2Lqo5S1QRVTahZs2beziAe2LoVbrvN/PLPPeezQDmOE1ZCCa9MAo4M+lyXf7pmrgO6AKjqjyJSFqihqn8BewPr54jISuBYwGf/DmbIENiwASZPdpF3HCfshNKinw0cIyINRaQM0B2YmKnM/4AzAUSkMVAW2CAiNQOduYjIUcAxwKpwGR8X/PijdcAOGgStWsXaGsdx4pBcW/SqmiIiA4EpQEngTVX9TUSGAomqOhG4A3hNRG7H3Dq9VVVF5FRgqIikAKnADaq6OWJnU9TYvx+uvx7q1IGhQ2NtjeM4cUpII2NVdTLWyRq87sGg5UVA+yz2Gw+ML6CN8csLL8DChfDJJ1CxYqytcRwnTvGRsbFi9Wp4+GHLYXPxxbG2xnGcOMaFPhao2qAoEXj55Vhb4zhOnONJzWLBxx/D55/DsGFQr16srXEcJ87xFn202b7dImxatrT3OGL7dpvl0HGcwoULfbS5/35Yt85CKkvFzwPVjh1w9NHw4IO5l3UcJ7q40EeTxERLc3DTTdC2baytCStjxsDGjfDaaxY16jhO4cGFPlqkpFjMfO3a8NhjsbYmrKjC8OEWIbphg3U/OI5TeHChjxavvAJz58KLL0LlyrG2Jqx89x0sWgTPPguHHw5vvhlrixzHCcaFPhqsWQMPPABdu8Lll8famrAzfDhUrQq9esG111rKnnXrYm2V4zjpuNBHg0GDLBxl+PC4mylq7Vob2Nu3r8102KePnerbb8faMsdx0nGhjzQTJ8Knn8JDD0HDhrG2JuyMGgVpaXDjjfb52GNtqts33zTfveM4sceFPpLs3GkjYJs1g3/9K9bWhJ19+0zou3Sx0Mp0+vaFZctg5szY2eY4zgFc6CPJQw+Zf37kSChdOtbWhJ1PPoE//4Sbbz54/RVXQIUK3ilb3Jg50zrliyqJiTB2LKxcGX9Poy70kWLePIuwGTAATjkl1tZEhOHDzRvVpcvB6ytUgG7dbHbEnTtjY5sTXd59Fzp2hDPOgL/+irU1eee116BdO7jqKmjUCGrVggsugEcfha+/hm3bYm1hwXChjwSpqRYzX706PPlkrK2JCAsXwowZ5pvPalKsvn3h77/hww+jb5sTXd56C66+2sYAbt0K/foVnRZxWhrce6+1x846C2bNgn//G84/31r2DzwAZ59tUWVNm8J119lNYeHCIpbuQ1UL1at169Za5HnlFVVQfffdWFsSMa6/XrVsWdWNG7Penpametxxqh06RNcuJ7qMGqUqonr22ap//636wgv20x8xItaW5c6ePao9epi9/fur7tv3zzJbtqhOmaI6dKjqueeqVqtm5UG1QgXV009XHTJE9dNPVdeti/45BINNBJWlrsZc2DO/irzQr12rWqmS6llnmdrFIVu3qh56qGrv3jmXe+op+4UtXRodu5zoMny4fb9du6ru3m3rUlNVO3dWLVdOdfHi2NqXE5s2qXbsaPY/8UTof9W0NNXly1XHjFG9+WbVhATVUqUOiP/xx6ved5/qL79E/+/vQh9NrrhC9ZBD7NcQp7z4ov1yZs/OuVxysmrJkqr33BMdu5zokd5yv+ACaxkHk5ysWr26aqtWqnv3xsa+nFi50p42y5RRHTu24PXt2qX6/feqzz6resYZqiVK2LU56ijVu+9WnTUrOqLvQh8tJk+2S/rII7G2JGKku2Tatg2t/AUXqNaurbp/f2TtcqLHM8/Yz/ySS7IX8k8+sTKDB0fXttz46SfVmjVVq1ZVnT49Msf46y/V115T7dLlQGu/Xj3V226zG0JqamSO60IfDb76SrVuXdXGjf/ZxIkjvvrKfjVvvRVa+fQ//GefRdYuJzo8/rh9n1dembVPO5j+/c1//+230bEtNz7+2FxKDRuqLlkSnWNu3mz/lQsusCcIUD38cHP7fPNNeBtALvSRZO5c64kC1fr1c/dnFHEuvli1Ro0DPtnc2LdPtVYta/05RZe0NNWHH7af+VVXhSZQO3eqHnOM6pFHWqdmLHn+ebvpnHSS6vr1sbFh2zbV995TvfRSu+GAPV30728dvrndOHOjwEIPdAGWAiuAwVlsrwdMA34BFgDnBm0bEthvKXBObscqMkL/+++qPXvaJaxWTfW55+K6Ja+q+scf5n/Mq8/9zjvtETZWfzCnYKSlWQcjqF57rWpKSuj7/vyzfffdu8cmNiElRXXQoAOupr//jr4NWbFzp+qHH9p1qVDB7Kta1Vr6+aVAQg+UBFYCRwFlgPlAk0xlRgE3BpabAKuDlucDhwANA/WUzOl4hV7oN25Uvf12ew4rW9ackLFurkSJe++1VtHvv+dtv99+s1/asGERMcuJIGlp1qEIqv365c+//Oijtv+YMeG3Lyd27lS96CI79u235+0GFU1271adMEH1mmusdZ9fCir0JwNTgj4PAYZkKjMSuCeo/MysygJTgJNzOl6hFfq//zYHZaVK1qy97jrVNWtibVXU2LPHHjMvuCB/+7drp9qkSeGLON23zx6bBwywTuMGDayV9fzzqj/+GPcPaTmSlmYdiKB6443570RMSbHxFJUq5b2RkF/+/FO1TRtrmLz0UnSOGWsKKvSXA68Hfb4aeCVTmcOBhUASsAVoHVj/CtArqNwbwOVZHGMAkAgk1qtXL1rXJTT277cu9COO0Ix4sl9/jbVVUeedd+z0v/wyf/uPGmX7z5oVXrvyw549qpMm2TiAqlU1Y/DLlVdadOyRR2pGXHSZMhZhNGiQ+VdXrix8N6tIkJpqbgRQvfXWgp/z77+b0HfoEPmW9aJFdsMuV84GMhUXCir0V2Qh9C9nKvMv4A490KJfhKVXGJ6F0F+W0/EKTYs+Lc2ep5o0scvUrl3k4rGKACefrNqoUf5bddu22R9vwIDw2hUqu3ZZ1EXPniY4oFq5surVV9vXnLlzee1aK3/33aqnnqpavvwB8a9ZU/X8880l8fXXdm7xRGqqfU9g/SvhurGNGWN1PvpoeOrLim+/Va1SxQIAfv45cscpjETDdfMbcGTQ51VArSLrupk505oeoHrssarjxxePZlw2zJ1rl+K55wpWzzXXqFasGL0OsR07VMeNs1Z6ulBXr25et8mT8zaYZ/9+G+04YoQ9CRx//AHhF1Ft2lS1b9/C8cRSEFJSVPv0saplKUAAACAASURBVPO6997w/uzT0izlQMmS4b9OqamqI0eqli5tEc6rVoW3/qJAQYW+VEC4GwZ1xjbNVOYLoHdguTGQDAjQNFNn7KpC3Rm7ZIl1zYPqYYfZv7qgMU9xwHXXWWt88+aC1fPtt3Zp3347PHZlxdat1nK86CLrK0//Km+4wVrf4Yxb3rzZ/Pv/93+WB6VKFRsU/f774TtGNNm/X7VXL7tmDz0UmbbNli02eKhRI7sRF5S0NHMntmhhdp9+esF/p0WVAgm97c+5wLJA1Mx9gXVDgQsDy02AHwKiPg/oHLTvfYH9lgJdcztWzIR++3Z7lq9QwTIYheNXGAds3mwiX5BogHTS0lSPPlq1U6eC15WZPXtMpEqXtl91nTqqt9yi+t130Yu22LjxwIPgU08VjYfArVttENyjj6q2bx9514qq3fBFLIqnIMyZo3rmmWZzgwaWQzBSo06LAgUW+mi+Yib0P/1kl+Pjj2NzfDVB2rMn/69I5BUZNswuy7x54akvPdRuxYrw1Kdq1+2yy6zeW24xz1us/vC7d6t262a23HBD4Ur9kJKiumCBdYz37WvdTyIHXFDHH2+JV6PB4MH5/7utWmWDttJdcc8/X7yjo9JxoQ+F0aPtcsQo1eLGjZYEKf1Pl99Xz57hexhJTbUWePv24alP1SJSS5RQvf/+8NSXlnag47CwxOmnptqgMjCXTqweDtets6iTwYPNpZE+MCd9jN+555rbacqU6A8F2bvXkp5Vr24d36GwcaOFe6YPYRkyxJ5IHCMnoS+FYyxZYtP9HXVUTA7/+OOwerXNPnjIIfmrIzkZXn0V5syBjz6yiRIKwn//a5MvPPJIweoJpm5dOOcc+M9/4OGHs560JC/cf7/NWztkSOGZlrdECZtvpmFDm2bx1FNh0iQ44ojIHnfxYpgyBX76yV5//GHrS5WCli3h2mttFqV27WyOX5HI2pMTZcrYrFStWkGfPvDFF3bdsmLXLpus7cknbcayPn3g//4P6tSJrs1FmuzuALF6xaxFf+GF9iwbA37/3VopffsWvK5vvrHOx/LlC97pef75Vle4XUIffqgFislP57nnrJ7+/QuvP3zyZMvdf+SRqgsXRuYYq1db/0S6G6ZePYs0GjZM9YcfLLS0sDJihNn8/PP/3JaSovrGG9bfAvZ7LIZDWEIGd92EwLHHWrahGHD11fYoGq6BtsnJqqedphnD1vPzR1+1yoQjXC6WYPbssUf2K67Ifx1vvWXnd+mlhXdoezpz59p4u0qVLPInXGzapPqvfx1wZdxzj2pSUvjqjwZpaTYG8ZBDrP8gfd2kSRayCjZg7bvvYmtnUcCFPjf27rXg3vvui/qh580zQQ335Bz795sPE1Rbtsz7PCh3322XJFJZHm691SJkNmzI+74TJ5ptZ5xRdDrh/vc/1WbNLMHX6NEFq2vXLovqqVLFfjt9+lj9RZW//rInx2bNbExieiOlUSN7+iusT2uFDRf63EjPuhXtrEtqkxNUrRq52N9Jk6z+ihVVP/ootH127bLOukg+4MybZ5f8xRfztt/06dZ6TUiwiNiixNatNsMkqD74YN4FLCXFbhJ161od550XOXdQtEmfsyd95PHw4T6EJa+40OfG+PF2KRITo3rYqVPtsM8+G9njrF5tj79gUQu5+dzTA5CmTo2sXa1bqzZvHrrgzZtnQx2OO85agUWRffsOjDy95prQ+j/S0lQ//1z1hBNsvzZtVKdNi7ipUeell2xytqJ2Ay8suNDnRnpwdxTj4FJTTejq1Qt9Eo+CsHfvgbzc7dpZbvnsSEiwYeSRfmROn1x6zpzcy65YYY/3devmbHtRIC3NBC19JGdOoY0//2wDzMBCXd9/310ZTta40OdGr14WFhFFxo2zqx/qlHzh4oMPzI1TrZo9Lmdm1iyz6+WXI2/L5s3WCZfbZAvJyTbGoFo1y0wYL4wZY/0UTZrYU1cwK1YcGHhVs6Z9H4Vxom2n8OBCnxutW9t0gFFi715rnZ1wQmwiRpYuNZcJWP9z8OjNa66xgTXRysh41VXWqZjdU82WLWbroYfa4OV4Y9o0O//atc1z+NdfNrq3dGkLkX3ggfjLjulEBhf6nEhLMxUZNChqh3z5ZbvyWbWoo8WuXZasDMw1sG6dRcAccohNMhEtvv7abBg79p/b/v7bcseULq363/9Gz6Zo89tvNt1w+fL2tFWypI32TU6OtWVOUSInoc9mLFoxIikJ/v4bjj8+Kofbvh2GDoVOnaBLl6gcMkvKlYPXX7cRqrNmwYknwq23wt69NpozWpx+OtSvD2+8cfD6/fuhWzf44Qd45x04++zo2RRtmjSxkawnnWTn+euvMHIkHH54rC1z4gUX+iVL7L1x46gcbtgw2LABnn46tkPQ07n2WhP6ypXhvffgtNMKnjohL5QoYUPap061FBAAaWlw3XWWNuDVV+HKK6NnT6yoXRu++QbGj49am8MpRrjQL15s71H4d/35pwn9FVdAmzYRP1zInHACzJ4N994Lzz8f/eP37m3vb71lkdR33AFjxliOnRtuiL49jhNveFKzJUugShU47LCIH2roUHONPP54xA+VZypWhMcei82x69eHM8+E0aMtydkLL8CgQXDffbGxx3HiDW/RL15srfkI+1GWLbMsi9dfD40aRfRQRZK+fS3b4gMPQM+e9mRRGFxbjhMPuNAvWRIV//x991kH6AMPRPxQRZKLL7YUxuefby377FLWOo6Td4q362brVnOcR9g/P2uW5Yd/+OGoeIiKJOXKwdKl9u4teccJL8Vb6KMQcaMKd98NtWoVnokxCivly8faAseJT4q30Ech4mbyZJg+HYYPtw5Px3GcaFO8PaFLlticZg0bRqT61FQYPNg6X/v3j8ghHMdxcsVb9MccY5NqRoAxY2yU4wcf2HS0juM4sSCkFr2IdBGRpSKyQkQGZ7H9eRGZF3gtE5GtQdtSg7ZNDKfxBSaCETe7d1uETZs2cPnlETmE4zhOSOTalBWRksBw4GwgCZgtIhNVdVF6GVW9Paj8LcCJQVXsVtWW4TM5TOzdCytXWkKVCPDKK5ZGZ8wYjyJxHCe2hNKibwusUNVVqroPGAdclEP5HsDYcBgXUVassKQqEeiI3bLFRr927WrJyxzHcWJJKEJfB1gT9DkpsO4fiEh9oCHwTdDqsiKSKCI/icjF2ew3IFAmccOGDSGaXkDSI24i4Lp54gnYtg2efDLsVTuO4+SZUIQ+K8eDZlO2O/CRqqYGraunqgnAVcALInL0PypTHaWqCaqaULNmzRBMCgPpMfTHHRfWatesgZdegquvhubNw1q14zhOvghF6JOAI4M+1wWSsynbnUxuG1VNDryvAr7lYP997Fi8GOrVg0MPDWu1Dz5o7488EtZqHcdx8k0oQj8bOEZEGopIGUzM/xE9IyLHAVWBH4PWVRWRQwLLNYD2wKLM+8aEJUvC7p9fuNBS7d5yi91DHMdxCgO5Cr2qpgADgSnAYuADVf1NRIaKyIVBRXsA4wJTWqXTGEgUkfnANODJ4GidmJGWFpHQyiFDbAKPIUPCWq3jOE6BCGmkkKpOBiZnWvdgps8PZ7HfTOCEAtgXGZKSYNeusLbov/gCPv8cnnoKqlULW7WO4zgFpnimQAhzxM3u3TBwoN03brstLFU6juOEjeKZAiE94iZMLfrHH4dVq2zOzzJlwlKl4zhO2Ci+LfqqVS13cAFZutTcNb16wemnh8E2x3GcMFM8hT494qaAuQlU4aabLELz2WfDZJvjOE6YKZ5Cv3hxWPzzY8eau+bxx33mKMdxCi/FT+g3b4a//iqwf37rVpsxqk0bGDAgTLY5juNEgOLXGRum6QPvvx82bLCQypIlw2CX4zhOhCh+LfowRNwkJsKrr5p/vnXrMNnlOI4TIYqf0C9eXKDpA1NT4YYbzCf/6KNhts1xHCcCFE/XzbHH5tvf8u9/w5w58N57lu7AcRynsFP8WvQFyHHz559w771w5pnQvXuY7XIcx4kQxUvo9+yxIaz59M/fcYdV8eqrPj2g4zhFh+Il9OnTB+ajRT91qrlr7rnHPD+O4zhFheIl9OnJzPLYot+71yJsjjrKUxA7jlP0KF6dsfmcPvCZZ2DZMktFXK5cBOxyHMeJIMWvRV+/PpQvH/Iuq1bBY4/B5ZdDly4RtM1xHCdCFC+hz2PEjarlmS9VCl54IYJ2OY7jRJDiI/Tp0wfmwT//8cfmrhk6FOrUiaBtjuM4EaT4CP2aNTYVVIgt+h074NZboUULm+zbcRynqFJ8OmPzGHHz8MOwdi18+KG5bhzHcYoqxadFn4eslQsWwIsvQv/+cPLJEbbLcRwnwhQfoV+8GKpVgxo1ciyWlmZJy6pWhSefjJJtjuM4ESQkoReRLiKyVERWiMjgLLY/LyLzAq9lIrI1aNu1IrI88Lo2nMbniRCnD3zzTfjxR4udr1YtSrY5juNEkFy9zyJSEhgOnA0kAbNFZKKqLkovo6q3B5W/BTgxsFwNeAhIABSYE9h3S1jPIhQWL4YLL8yxyMaNluKgY0e4Nna3JMdxnLASSou+LbBCVVep6j5gHHBRDuV7AGMDy+cAX6nq5oC4fwVEf9jRpk02HVQOHbGqcOedsH07jBjhScscx4kfQhH6OsCaoM9JgXX/QETqAw2Bb/Kyr4gMEJFEEUncsGFDKHbnjVw6Yn/80Vrxb71lGSqbNg2/CY7jOLEiFKHPqm2r2ZTtDnykqql52VdVR6lqgqom1KxZMwST8kg20wcuXQqXXgqnnAIrV9qkIo89Fv7DO47jxJJQhD4JODLoc10gOZuy3TngtsnrvpFj8WI45BBo0ACwCURuvNFa7l99ZSNfV6yA66/3ib4dx4k/QhH62cAxItJQRMpgYj4xcyEROQ6oCvwYtHoK0FlEqopIVaBzYF10CUwfuGNXSR56CBo1gtdfN7FfuRIeeAAOPTTqVjmO40SFXKNuVDVFRAZiAl0SeFNVfxORoUCiqqaLfg9gnKpq0L6bReQR7GYBMFRVN4f3FHJn/6LlvFb1bv6vEfz1F1xxBTz+uAm+4zhOvCNBulwoSEhI0MTExLDUpQrjx+7j3p6rWc6xnHYaPP00tG0bluodx3EKDSIyR1UTstoWtyNjp0+39AVX9CxDGfYx6a7vmDbNRd5xnOJH3An9b7/BBRfAaadBUhK8ecPPzKcF511V2WPjHccplsSN0G/cCP36QfPmMGMGPPEELF8OfWp/QUlRn9HbcZxiS9wk4C1RAiZNshzy990H1asHNixZkufpAx3HceKJuBH6atXg99+zmLx78eI8TR/oOI4Tb8SN6wayEPm0NBv+mofpAx3HceKNuBL6f/DHH7Bnj7foHccp1sS30GeT48ZxHKc4Ed9Cnz5PrLfoHccpxsS30C9ZYuE3uUwf6DiOE8/ETdRNlnjEjVPE2b9/P0lJSezZsyfWpjiFhLJly1K3bl1Kly4d8j7xLfRLlsDFF8faCsfJN0lJSVSsWJEGDRogPrS72KOqbNq0iaSkJBo2bBjyfvHrutm40V7eoneKMHv27KF69eou8g4AIkL16tXz/IQXv0LvETdOnOAi7wSTn99D/Au9t+gdxynmxK/QL14MZctCvXqxtsRxiiybNm2iZcuWtGzZktq1a1OnTp2Mz/v27Qupjj59+rB06dIcywwfPpx33303HCY7WRC/nbFLlsBxx/kksI5TAKpXr868efMAePjhh6lQoQJ33nnnQWVUFVWlRIms242jR4/O9Tg333xzwY2NMikpKZQqVTQkNL5b9O6fd+KJ226DTp3C+7rttnyZsmLFCpo1a8YNN9xAq1atWLduHQMGDCAhIYGmTZsydOjQjLIdOnRg3rx5pKSkUKVKFQYPHkyLFi04+eST+euvvwC4//77eeGFFzLKDx48mLZt23Lccccxc+ZMAP7++28uu+wyWrRoQY8ePUhISMi4CQXz0EMP0aZNmwz70mfRW7ZsGWeccQYtWrSgVatWrF69GoDHH3+cE044gRYtWnDfffcdZDPAn3/+SaPAvKOvv/463bt35/zzz6dr165s376dM844g1atWtG8eXMmTZqUYcfo0aNp3rw5LVq0oE+fPmzdupWjjjqKlJQUALZu3UrDhg1JTU3N13eQF+JT6HfvhtWr3T/vOBFk0aJFXHfddfzyyy/UqVOHJ598ksTERObPn89XX33FokWL/rHPtm3bOO2005g/fz4nn3wyb775ZpZ1qyo///wzzzzzTMZN4+WXX6Z27drMnz+fwYMH88svv2S576233srs2bNZuHAh27Zt48svvwSgR48e3H777cyfP5+ZM2dSq1YtPvvsM7744gt+/vln5s+fzx133JHref/444+MGTOGr776inLlyjFhwgTmzp3L119/ze233w7A/Pnzeeqpp/j222+ZP38+w4YNo0qVKrRv3z7Dnvfee48rr7ySklHwOhSN5468smyZTRjrLXonngi0eAsLRx99NG3atMn4PHbsWN544w1SUlJITk5m0aJFNGnS5KB9ypUrR9euXQFo3bo1M2bMyLLuSy+9NKNMesv7+++/55577gGgRYsWNG3aNMt9p06dyjPPPMOePXvYuHEjrVu3pl27dmzcuJELLrgAsEFHAF9//TV9+/alXCD1bbVq1XI9786dO1O1alXAbkj33HMP33//PSVKlGDNmjVs3LiRb775hm7dumXUl/7er18/XnrpJc4//3xGjx7NmDFjcj1eOIhPoffQSseJOIceemjG8vLly3nxxRf5+eefqVKlCr169coy1rtMmTIZyyVLlsxwY2TmkEMO+UeZdBdMTuzatYuBAwcyd+5c6tSpw/33359hR1Zhiaqa5fpSpUqRlpYG8I/zCD7vt99+m23btjF37lxKlSpF3bp12bNnT7b1nnbaaQwcOJBp06ZRunRpjo+SRoXkuhGRLiKyVERWiMjgbMpcKSKLROQ3EXkvaH2qiMwLvCaGy/AcWbwYRHz6QMeJEtu3b6dixYpUqlSJdevWMWXKlLAfo0OHDnzwwQcALFy4MEvX0O7duylRogQ1atRgx44djB8/HoCqVatSo0YNPvvsM8DEe9euXXTu3Jk33niD3bt3A7B582YAGjRowJw5cwD46KOPsrVp27Zt1KpVi1KlSvHVV1+xdu1aAM466yzGjRuXUV/6O0CvXr3o2bMnffr0KdD1yAu5Cr2IlASGA12BJkAPEWmSqcwxwBCgvao2BYJ7eHarasvA68LwmZ4DS5ZAgwZZzETiOE4kaNWqFU2aNKFZs2b079+f9u3bh/0Yt9xyC2vXrqV58+YMGzaMZs2aUbly5YPKVK9enWuvvZZmzZpxySWXcNJJJ2Vse/fddxk2bBjNmzenQ4cObNiwgfPPP58uXbqQkJBAy5Ytef755wG46667ePHFFznllFPYsmVLtjZdffXVzJw5k4SEBD788EOOOeYYAJo3b87dd9/NqaeeSsuWLbnrrrsy9unZsyfbtm2jW7du4bw8OSK5PQ6JyMnAw6p6TuDzEABVfSKozNPAMlV9PYv9d6pqhVANSkhI0MTExFCLZ02LFlC3Lnz+ecHqcZwYs3jxYhp7UAFg4YwpKSmULVuW5cuX07lzZ5YvX15kQhzTGTduHFOmTAkp7DQ7svpdiMgcVU3IqnwoV6gOsCbocxJwUqYyxwYO9ANQErsxfBnYVlZEEoEU4ElV/TTzAURkADAAoF5BBzilplpn7FlnFawex3EKFTt37uTMM88kJSUFVWXkyJFFTuRvvPFGvv7664zIm2gRylXKKrFC5seAUsAxQCegLjBDRJqp6lagnqomi8hRwDcislBVVx5UmeooYBRYiz6P53AwPn2g48QlVapUyfCbF1VGjBgRk+OG0hmbBBwZ9LkukJxFmQmqul9VfweWYsKPqiYH3lcB3wInFtDmnPGIG8dxnIMIRehnA8eISEMRKQN0BzJHz3wKnA4gIjUwV84qEakqIocErW8P/LOrPJz49IGO4zgHkavrRlVTRGQgMAXzv7+pqr+JyFAgUVUnBrZ1FpFFQCpwl6puEpFTgJEikobdVJ5U1cgK/ZIlNnVg9eoRPYzjOE5RIaSeDFWdDEzOtO7BoGUF/hV4BZeZCZxQcDPzgE8f6DiOcxDxl+tmyRL3zztOmOjUqdM/Bj+98MIL3HTTTTnuV6GCRVQnJydz+eWXZ1t3bqHUL7zwArt27cr4fO6557J169ZQTHeCiC+h37ABNm3yFr3jhIkePXowbty4g9aNGzeOHj16hLT/EUcckePI0tzILPSTJ0+mSpUq+a4v2qhqRiqFWBJfQu8RN04cE4ssxZdffjmTJk1i7969AKxevZrk5GQ6dOiQEdfeqlUrTjjhBCZMmPCP/VevXk2zZs0AS0/QvXt3mjdvTrdu3TLSDoDFl6enOH7ooYcAeOmll0hOTub000/n9NNPByw1wcaNGwF47rnnaNasGc2aNctIcbx69WoaN25M//79adq0KZ07dz7oOOl89tlnnHTSSZx44omcddZZrF+/HrBY/T59+nDCCSfQvHnzjBQKX375Ja1ataJFixaceeaZgOXnf/bZZzPqbNasGatXr86w4aabbqJVq1asWbMmy/MDmD17NqeccgotWrSgbdu27Nixg44dOx6Ufrl9+/YsWLAg5y8qF4rWaIPc8Igbxwkr1atXp23btnz55ZdcdNFFjBs3jm7duiEilC1blk8++YRKlSqxceNG2rVrx4UXXpjtnKYjRoygfPnyLFiwgAULFtCqVauMbY899hjVqlUjNTWVM888kwULFjBo0CCee+45pk2bRo0aNQ6qa86cOYwePZpZs2ahqpx00kmcdtppVK1aleXLlzN27Fhee+01rrzySsaPH0+vXr0O2r9Dhw789NNPiAivv/46Tz/9NMOGDeORRx6hcuXKLFy4EIAtW7awYcMG+vfvz/Tp02nYsOFBeWuyY+nSpYwePZpXX3012/M7/vjj6datG++//z5t2rRh+/btlCtXjn79+vGf//yHF154gWXLlrF3716aN2+ep+8tM/El9EuWWH4bnz7QiUNilaU43X2TLvTpOeRVlXvvvZfp06dTokQJ1q5dy/r166ldu3aW9UyfPp1BgwYBlgsmWLw++OADRo0aRUpKCuvWrWPRokU5itv333/PJZdckpFJ8tJLL2XGjBlceOGFNGzYkJYtWwIHpzkOJikpiW7durFu3Tr27dtHw4YNAUtbHOyqqlq1Kp999hmnnnpqRplQUhnXr1+fdu3a5Xh+IsLhhx+ekeq5UqVKAFxxxRU88sgjPPPMM7z55pv07t071+PlRny5bhYvtukDs5nSzHGcvHPxxRczdepU5s6dy+7duzNa4u+++y4bNmxgzpw5zJs3j8MOOyzL1MTBZNXa//3333n22WeZOnUqCxYs4Lzzzsu1npxydKWnOIbsUyHfcsstDBw4kIULFzJy5MiM42WVXjiUVMZwcDrj4FTG2Z1fdvWWL1+es88+mwkTJvDBBx9w1VVXZXuuoRJfiugRN44TdipUqECnTp3o27fvQZ2w6Sl6S5cuzbRp0/jjjz9yrOfUU0/NmAD8119/zfA7b9++nUMPPZTKlSuzfv16vvjii4x9KlasyI4dO7Ks69NPP2XXrl38/ffffPLJJ3Ts2DHkc9q2bRt16tQB4K233spY37lzZ1555ZWMz1u2bOHkk0/mu+++4/fffwcOTmU8d+5cAObOnZuxPTPZnd/xxx9PcnIys2fPBmDHjh0ZN6V+/foxaNAg2rRpE9ITRG7Ej9Dv2mV5btw/7zhhp0ePHsyfP5/u3btnrOvZsyeJiYkkJCTw7rvv5jqJxo033sjOnTtp3rw5Tz/9NG3btgVstqgTTzyRpk2b0rdv34NSHA8YMICuXbtmdMam06pVK3r37k3btm056aST6NevHyeeGHp2lYcffpgrrriCjh07HuT/v//++9myZQvNmjWjRYsWTJs2jZo1azJq1CguvfRSWrRokZFe+LLLLmPz5s20bNmSESNGcGw2819kd35lypTh/fff55ZbbqFFixacffbZGU8FrVu3plKlSmHLWZ9rmuJok+80xX/9ZSEEffrA2WeH3zDHiQGeprh4kpycTKdOnViyZAklsnBF5zVNcfy06GvVgvfec5F3HKdI8/bbb3PSSSfx2GOPZSny+SG+om4cx3GKONdccw3XXHNNWOuMnxa948Qphc296sSW/PweXOgdpxBTtmxZNm3a5GLvACbymzZtomzZsnnaz103jlOIqVu3LklJSWzYsCHWpjiFhLJly1K3bt087eNC7ziFmNKlS2eMyHSc/OKuG8dxnDjHhd5xHCfOcaF3HMeJcwrdyFgR2QDknDQjZ2oAG8NkTiRw+wqG21cw3L6CUZjtq6+qNbPaUOiEvqCISGJ2w4ALA25fwXD7CobbVzAKu33Z4a4bx3GcOMeF3nEcJ86JR6EfFWsDcsHtKxhuX8Fw+wpGYbcvS+LOR+84juMcTDy26B3HcZwgXOgdx3HinCIp9CLSRUSWisgKERmcxfZDROT9wPZZItIgirYdKSLTRGSxiPwmIrdmUaaTiGwTkXmB14PRsi/IhtUisjBw/H9M6SXGS4FruEBEWkXRtuOCrs08EdkuIrdlKhPVaygib4rIXyLya9C6aiLylYgsD7xXzWbfawNllovItVG07xkRWRL4/j4RkSrZ7JvjbyGC9j0sImuDvsNzs9k3x/97BO17P8i21SIyL5t9I379CoyqFqkXUBJYCRwFlAHmA00ylbkJ+HdguTvwfhTtOxxoFViuCCzLwr5OwKQYX8fVQI0ctp8LfAEI0A6YFcPv+09sMEjMriFwKtAK+DVo3dPA4MDyYOCpLParBqwKvFcNLFeNkn2dgVKB5aeysi+U30IE7XsYuDOE7z/H/3uk7Mu037L59gAAA3tJREFUfRjwYKyuX0FfRbFF3xZYoaqrVHUfMA64KFOZi4D0qd0/As4UEYmGcaq6TlXnBpZ3AIuBOtE4dpi5CHhbjZ+AKiJyeAzsOBNYqaoFGS1dYFR1OrA50+rg39lbwMVZ7HoO8JWqblbVLcBXQJdo2Keq/1XVlMDHn4C85bYNI9lcv1AI5f9eYHKyL6AdVwJjw33caFEUhb4OsCbocxL/FNKMMoEf+jagelSsCyLgMjoRmJXF5pNFZL6IfCEiTaNqmKHAf0VkjogMyGJ7KNc5GnQn+z9YrK/hYaq6DuwGD9TKokxhuY59sSe0rMjttxBJBgZcS29m4/oqDNevI7BeVZdnsz2W1y8kiqLQZ9UyzxwjGkqZiCIiFYDxwG2quj3T5rmYK6IF8DLwaTRtC9BeVVsBXYGbReTUTNsLwzUsA1wIfJjF5sJwDUOhMFzH+4AU4N1siuT2W4gUI4CjgZbAOsw9kpmYXz+gBzm35mN1/UKmKAp9EnBk0Oe6QHJ2ZUSkFFCZ/D025gsRKY2J/Luq+nHm7aq6XVV3BpYnA6VFpEa07AscNznw/hfwCfaIHEwo1znSdAXmqur6zBsKwzUE1qe7swLvf2VRJqbXMdD5ez7QUwMO5cyE8FuICKq6XlVTVTUNeC2b48b6+pUCLgXez65MrK5fXiiKQj8bOEZEGgZafN2BiZnKTATSoxsuB77J7kcebgL+vDeAxar6XDZlaqf3GYhIW+x72BQN+wLHPFREKqYvY512v2YqNhG4JhB90w7Ylu6miCLZtqRifQ0DBP/OrgUmZFFmCtBZRKoGXBOdA+sijoh0Ae4BLlTVXdmUCeW3ECn7gvt8LsnmuKH83yPJWcASVU3KamMsr1+eiHVvcH5eWETIMqw3/r7AuqHYDxqgLPa4vwL4GTgqirZ1wB4tFwDzAq9zgRuAGwJlBgK/YREEPwGnRPn6HRU49vyAHenXMNhGAYYHrvFCICHKNpbHhLty0LqYXUPshrMO2I+1Mq/D+n2mAssD79UCZROA14P27Rv4La4A+kTRvhWYfzv9d5geiXYEMDmn30KU7BsT+G0twMT78Mz2BT7/4/8eDfsC6/+T/psLKhv161fQl6dAcBzHiXOKouvGcRzHyQMu9I7jOHGOC73jOE6c40LvOI4T57jQO47jxDku9I7jOHGOC73jOE6c8/+Xrmf89I9uqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('garbage_model-pretrained.h5')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()#saving converted model in \"converted_model.tflite\" file\n",
    "open(\"converted_garbage_model2.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "model1 = tf.keras.models.load_model('garbage_model-pretrained.h5')\n",
    "converter1 = tf.lite.TFLiteConverter.from_keras_model(model1)\n",
    "converter1.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter1.convert()#saving converted model in \"converted_quant_model.tflite\" file\n",
    "open(\"converted_garbage_quant_model2.tflite\", \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
